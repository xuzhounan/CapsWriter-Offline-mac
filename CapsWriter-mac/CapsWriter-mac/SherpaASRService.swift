import Foundation
import AVFoundation
import Combine

// MARK: - Transcript Data Models

struct TranscriptEntry: Identifiable, Equatable {
    let id = UUID()
    let timestamp: Date
    let text: String
    let isPartial: Bool
    
    var formattedTime: String {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss"
        return formatter.string(from: timestamp)
    }
}

// MARK: - Sherpa-ONNX C API Helper Functions

/// Convert a String from swift to a `const char*` so that we can pass it to
/// the C language.
func toCPointer(_ s: String) -> UnsafePointer<Int8>! {
  let cs = (s as NSString).utf8String
  return UnsafePointer<Int8>(cs)
}

/// Return an instance of SherpaOnnxOnlineParaformerModelConfig.
func sherpaOnnxOnlineParaformerModelConfig(
  encoder: String = "",
  decoder: String = ""
) -> SherpaOnnxOnlineParaformerModelConfig {
  return SherpaOnnxOnlineParaformerModelConfig(
    encoder: toCPointer(encoder),
    decoder: toCPointer(decoder)
  )
}

/// Return an instance of SherpaOnnxOnlineTransducerModelConfig.
func sherpaOnnxOnlineTransducerModelConfig(
  encoder: String = "",
  decoder: String = "",
  joiner: String = ""
) -> SherpaOnnxOnlineTransducerModelConfig {
  return SherpaOnnxOnlineTransducerModelConfig(
    encoder: toCPointer(encoder),
    decoder: toCPointer(decoder),
    joiner: toCPointer(joiner)
  )
}

/// Return an instance of SherpaOnnxOnlineZipformer2CtcModelConfig.
func sherpaOnnxOnlineZipformer2CtcModelConfig(
  model: String = ""
) -> SherpaOnnxOnlineZipformer2CtcModelConfig {
  return SherpaOnnxOnlineZipformer2CtcModelConfig(
    model: toCPointer(model)
  )
}

/// Return an instance of SherpaOnnxOnlineModelConfig.
func sherpaOnnxOnlineModelConfig(
  tokens: String = "",
  transducer: SherpaOnnxOnlineTransducerModelConfig = sherpaOnnxOnlineTransducerModelConfig(),
  paraformer: SherpaOnnxOnlineParaformerModelConfig = sherpaOnnxOnlineParaformerModelConfig(),
  zipformer2Ctc: SherpaOnnxOnlineZipformer2CtcModelConfig = sherpaOnnxOnlineZipformer2CtcModelConfig(),
  numThreads: Int = 1,
  provider: String = "cpu",
  debug: Bool = false,
  modelType: String = "",
  modelingUnit: String = "",
  bpeVocab: String = ""
) -> SherpaOnnxOnlineModelConfig {
  return SherpaOnnxOnlineModelConfig(
    transducer: transducer,
    paraformer: paraformer,
    zipformer2_ctc: zipformer2Ctc,
    tokens: toCPointer(tokens),
    num_threads: Int32(numThreads),
    provider: toCPointer(provider),
    debug: debug ? 1 : 0,
    model_type: toCPointer(modelType),
    modeling_unit: toCPointer(modelingUnit),
    bpe_vocab: toCPointer(bpeVocab),
    tokens_buf: nil,
    tokens_buf_size: 0
  )
}

/// Return an instance of SherpaOnnxFeatureConfig.
func sherpaOnnxFeatureConfig(
  sampleRate: Int = 16000,
  featureDim: Int = 80
) -> SherpaOnnxFeatureConfig {
  return SherpaOnnxFeatureConfig(
    sample_rate: Int32(sampleRate),
    feature_dim: Int32(featureDim)
  )
}

/// Return an instance of SherpaOnnxOnlineRecognizerConfig.
func sherpaOnnxOnlineRecognizerConfig(
  featConfig: SherpaOnnxFeatureConfig = sherpaOnnxFeatureConfig(),
  modelConfig: SherpaOnnxOnlineModelConfig = sherpaOnnxOnlineModelConfig(),
  decodingMethod: String = "greedy_search",
  maxActivePaths: Int = 4,
  enableEndpoint: Bool = false,
  rule1MinTrailingSilence: Float = 2.4,
  rule2MinTrailingSilence: Float = 1.2,
  rule3MinUtteranceLength: Float = 20.0,
  hotwordsFile: String = "",
  hotwordsScore: Float = 1.5
) -> SherpaOnnxOnlineRecognizerConfig {
  return SherpaOnnxOnlineRecognizerConfig(
    feat_config: featConfig,
    model_config: modelConfig,
    decoding_method: toCPointer(decodingMethod),
    max_active_paths: Int32(maxActivePaths),
    enable_endpoint: enableEndpoint ? 1 : 0,
    rule1_min_trailing_silence: rule1MinTrailingSilence,
    rule2_min_trailing_silence: rule2MinTrailingSilence,
    rule3_min_utterance_length: rule3MinUtteranceLength,
    hotwords_file: toCPointer(hotwordsFile),
    hotwords_score: hotwordsScore,
    ctc_fst_decoder_config: SherpaOnnxOnlineCtcFstDecoderConfig(),
    rule_fsts: nil,
    rule_fars: nil,
    blank_penalty: 0.0,
    hotwords_buf: nil,
    hotwords_buf_size: 0,
    hr: SherpaOnnxHomophoneReplacerConfig()
  )
}

// MARK: - Speech Recognition Delegate Protocol

protocol SpeechRecognitionDelegate: AnyObject {
    func speechRecognitionDidReceivePartialResult(_ text: String)
    func speechRecognitionDidReceiveFinalResult(_ text: String)
    func speechRecognitionDidDetectEndpoint()
}

// MARK: - Pure ASR Service Class

class SherpaASRService: ObservableObject {
    // MARK: - Published Properties
    @Published var logs: [String] = []
    @Published var transcript: String = ""
    @Published var isServiceRunning: Bool = false
    @Published var isRecognizing: Bool = false
    @Published var isInitialized: Bool = false
    @Published var transcriptHistory: [TranscriptEntry] = []
    @Published var partialTranscript: String = ""
    
    // MARK: - Private Properties
    private var recognizer: OpaquePointer?
    private var stream: OpaquePointer?
    private let processingQueue = DispatchQueue(label: "com.capswriter.speech-recognition", qos: .userInitiated)
    private let cleanupQueue = DispatchQueue(label: "com.capswriter.sherpa-cleanup", qos: .utility)
    private static var logCounter = 0
    
    // Mock mode flag - ËÆæÁΩÆ‰∏∫ false Êù•ÂêØÁî®ÁúüÂÆûÊ®°Âûã
    private let isMockMode = false
    
    // Audio configuration
    private let sampleRate: Double = 16000
    
    // Model configuration
    private let modelPath: String
    private let tokensPath: String
    private let encoderPath: String
    private let decoderPath: String
    
    // Delegate
    weak var delegate: SpeechRecognitionDelegate?
    
    // MARK: - Initialization
    init() {
        // Initialize model paths
        let bundle = Bundle.main
        self.modelPath = bundle.path(forResource: "paraformer-zh-streaming", ofType: nil, inDirectory: "models") ?? ""
        self.tokensPath = "\(modelPath)/tokens.txt"
        self.encoderPath = "\(modelPath)/encoder.onnx"
        self.decoderPath = "\(modelPath)/decoder.onnx"
        
        addLog("üß† SherpaASRService ÂàùÂßãÂåñÔºàÁ∫ØËØÜÂà´ÊúçÂä°Ôºâ")
        addLog("üìÅ Ê®°ÂûãË∑ØÂæÑ: \(modelPath)")
    }
    
    deinit {
        print("üõë SherpaASRService deinit ÂºÄÂßã")
        // ‰ΩøÁî®‰∏ìÁî®ÈòüÂàóËøõË°åÊ∏ÖÁêÜÔºåÈÅøÂÖç‰∏ªÁ∫øÁ®ãÈòªÂ°û
        cleanupQueue.sync {
            self.cleanupRecognizer()
        }
        print("üõë SherpaASRService deinit ÂÆåÊàê")
    }
    
    // MARK: - Public Methods
    
    func startService() {
        addLog("üîÑ Ê≠£Âú®ÂêØÂä®ËØ≠Èü≥ËØÜÂà´ÊúçÂä°...")
        
        guard !isServiceRunning else {
            addLog("‚ö†Ô∏è ÊúçÂä°Â∑≤Âú®ËøêË°å‰∏≠")
            return
        }
        
        // Á´ãÂç≥Ê†áËÆ∞ÊúçÂä°‰∏∫ÂêØÂä®Áä∂ÊÄÅÔºåÂêéÂè∞ÂºÇÊ≠•ÂàùÂßãÂåñËØÜÂà´Âô®
        isServiceRunning = true
        
        // ÂºÇÊ≠•ÂàùÂßãÂåñËØÜÂà´Âô®ÔºåÈÅøÂÖçÈòªÂ°ûË∞ÉÁî®Á∫øÁ®ã
        processingQueue.async { [weak self] in
            RecordingState.shared.updateInitializationProgress("Ê≠£Âú®ÂàùÂßãÂåñËØÜÂà´Âô®...")
            self?.initializeRecognizer()
            
            DispatchQueue.main.async {
                self?.isInitialized = true
                RecordingState.shared.updateInitializationProgress("ËØÜÂà´Âô®Â∑≤Â∞±Áª™")
                self?.addLog("‚úÖ ËØ≠Èü≥ËØÜÂà´ÊúçÂä°Â∑≤ÂêØÂä®")
            }
        }
    }
    
    func stopService() {
        addLog("üõë Ê≠£Âú®ÂÅúÊ≠¢ËØ≠Èü≥ËØÜÂà´ÊúçÂä°...")
        
        // ‰ΩøÁî®‰∏ìÁî®ÈòüÂàóËøõË°åÊ∏ÖÁêÜÔºåÈÅøÂÖçÈòªÂ°ûË∞ÉÁî®Á∫øÁ®ã
        cleanupQueue.async { [weak self] in
            self?.cleanupRecognizer()
        }
        
        isServiceRunning = false
        isRecognizing = false
        isInitialized = false
        addLog("‚úÖ ËØ≠Èü≥ËØÜÂà´ÊúçÂä°Â∑≤ÂÅúÊ≠¢")
    }
    
    func startRecognition() {
        guard isServiceRunning else {
            addLog("‚ùå ÊúçÂä°Êú™ÂêØÂä®ÔºåÊó†Ê≥ïÂºÄÂßãËØÜÂà´")
            return
        }
        
        guard isInitialized else {
            addLog("‚è≥ ËØÜÂà´Âô®Ê≠£Âú®ÂàùÂßãÂåñ‰∏≠ÔºåËØ∑Á®çÂêéÂÜçËØï...")
            // Âª∂ËøüÈáçËØï
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                self.startRecognition()
            }
            return
        }
        
        guard !isRecognizing else {
            addLog("‚ö†Ô∏è ËØÜÂà´Â∑≤Âú®ËøõË°å‰∏≠")
            return
        }
        
        addLog("üß† ÂºÄÂßãËØ≠Èü≥ËØÜÂà´Â§ÑÁêÜ...")
        
        // Á°Æ‰øùËØÜÂà´Âô®Â∑≤ÂàùÂßãÂåñ
        guard recognizer != nil && stream != nil else {
            addLog("‚ùå ËØÜÂà´Âô®Êú™ÂàùÂßãÂåñÔºåÊó†Ê≥ïÂºÄÂßãËØÜÂà´")
            return
        }
        
        isRecognizing = true
        
        if isMockMode {
            addLog("üîÑ Ê®°ÊãüÊ®°ÂºèÔºöË∑≥ËøáSherpaËØÜÂà´Âô®ÈáçÁΩÆ")
        } else {
            // Âè™ÊúâÁúüÂÆûÊ®°ÂºèÊâçÊ£ÄÊü•Âπ∂Ë∞ÉÁî®Sherpa CÂáΩÊï∞
            guard let recognizer = self.recognizer else {
                addLog("‚ùå recognizer Êú™ÂàùÂßãÂåñ")
                isRecognizing = false
                return
            }
            guard let stream = self.stream else {
                addLog("‚ùå stream Êú™ÂàùÂßãÂåñ") 
                isRecognizing = false
                return
            }
            
            // ÈáçÁΩÆÈü≥È¢ëÊµÅÂáÜÂ§áÊñ∞ÁöÑËØÜÂà´‰ºöËØù
            SherpaOnnxOnlineStreamReset(recognizer, stream)
            addLog("üîÑ Èü≥È¢ëÊµÅÂ∑≤ÈáçÁΩÆÔºåÂáÜÂ§áÊñ∞ÁöÑËØÜÂà´‰ºöËØù")
        }
    }
    
    func stopRecognition() {
        guard isRecognizing else {
            addLog("‚ö†Ô∏è ËØÜÂà´Êú™Âú®ËøõË°å‰∏≠")
            return
        }
        
        addLog("‚èπÔ∏è ÂÅúÊ≠¢ËØ≠Èü≥ËØÜÂà´Â§ÑÁêÜ...")
        isRecognizing = false
        
        // Get final result from sherpa-onnx
        if let finalResult = getFinalResult() {
            transcript = finalResult
            addLog("üìù ÊúÄÁªàËØÜÂà´ÁªìÊûú: \(finalResult)")
            delegate?.speechRecognitionDidReceiveFinalResult(finalResult)
        }
        
        addLog("‚úÖ ËØ≠Èü≥ËØÜÂà´Â§ÑÁêÜÂ∑≤ÂÅúÊ≠¢")
    }
    
    // MARK: - Transcript Management
    
    func addTranscriptEntry(text: String, isPartial: Bool) {
        guard !text.isEmpty else { return }
        
        let entry = TranscriptEntry(
            timestamp: Date(),
            text: text,
            isPartial: isPartial
        )
        
        // Âú®‰∏ªÁ∫øÁ®ãÊõ¥Êñ∞UI
        DispatchQueue.main.async {
            self.transcriptHistory.append(entry)
            
            // ‰øùÊåÅÂéÜÂè≤ËÆ∞ÂΩï‰∏çË∂ÖËøá100Êù°
            if self.transcriptHistory.count > 100 {
                self.transcriptHistory.removeFirst(self.transcriptHistory.count - 100)
            }
        }
        
        addLog("üìù Ê∑ªÂä†ËΩ¨ÂΩïÊù°ÁõÆ: \(text)")
    }
    
    func clearTranscriptHistory() {
        DispatchQueue.main.async {
            self.transcriptHistory.removeAll()
            self.partialTranscript = ""
        }
        addLog("üóëÔ∏è ËΩ¨ÂΩïÂéÜÂè≤Â∑≤Ê∏ÖÁ©∫")
    }
    
    // MARK: - Audio Processing Interface
    
    func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        // Ê∑ªÂä†Êé•Êî∂Èü≥È¢ëÁºìÂÜ≤Âå∫ÁöÑË∞ÉËØïÊó•ÂøóÔºàÊØè100Â∏ßËæìÂá∫‰∏ÄÊ¨°Ôºâ
        Self.logCounter += 1
        if Self.logCounter % 100 == 0 {
            addLog("üì• ASRÊúçÂä°Â∑≤Êé•Êî∂ \(Self.logCounter) ‰∏™Èü≥È¢ëÁºìÂÜ≤Âå∫ÔºåÂΩìÂâçÁºìÂÜ≤Âå∫Â§ßÂ∞è: \(buffer.frameLength)")
        }
        
        guard isRecognizing else { 
            if Self.logCounter % 100 == 0 {
                addLog("‚ö†Ô∏è ASRÊúçÂä°Êú™Âú®ËØÜÂà´Áä∂ÊÄÅÔºåË∑≥ËøáÈü≥È¢ëÂ§ÑÁêÜ")
            }
            return 
        }
        
        // Process audio data in background queue
        processingQueue.async { [weak self] in
            self?.processAudioDataSafely(buffer)
        }
    }
    
    // MARK: - Private Methods
    
    private func addLog(_ message: String) {
        let timestamp = DateFormatter.logFormatter.string(from: Date())
        let logMessage = "[\(timestamp)] \(message)"
        
        DispatchQueue.main.async {
            self.logs.append(logMessage)
            // Keep only last 100 log entries
            if self.logs.count > 100 {
                self.logs.removeFirst(self.logs.count - 100)
            }
        }
        
        print(logMessage)
    }
    
    private func initializeRecognizer() {
        addLog("üß† ÂàùÂßãÂåñ Sherpa-ONNX ËØÜÂà´Âô®...")
        RecordingState.shared.updateInitializationProgress("Ê≠£Âú®Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂...")
        
        // Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
        addLog("üìÇ Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂...")
        addLog("  - Ê®°ÂûãË∑ØÂæÑ: \(modelPath)")
        addLog("  - ÁºñÁ†ÅÂô®: \(encoderPath)")
        addLog("  - Ëß£Á†ÅÂô®: \(decoderPath)")
        addLog("  - ËØçÊ±áË°®: \(tokensPath)")
        
        guard FileManager.default.fileExists(atPath: modelPath) else {
            addLog("‚ùå Ê®°ÂûãÁõÆÂΩï‰∏çÂ≠òÂú®: \(modelPath)")
            addLog("‚ö†Ô∏è ËØÜÂà´Âô®ÂàùÂßãÂåñÂ§±Ë¥•ÔºåÊó†Ê≥ïÂ§ÑÁêÜÈü≥È¢ë")
            RecordingState.shared.updateInitializationProgress("Ê®°ÂûãÊñá‰ª∂Áº∫Â§±")
            return
        }
        
        if isMockMode {
            // Ê®°ÊãüÊ®°ÂºèÔºö‰∏çÂàõÂª∫ÁúüÂÆûÁöÑSherpaÂØπË±°Ôºå‰øùÊåÅnilÁä∂ÊÄÅ
            addLog("üîß Ê®°ÊãüÊ®°ÂºèÔºö‰∏çÂàõÂª∫ÁúüÂÆûËØÜÂà´Âô®")
            addLog("‚úÖ Ê®°ÊãüËØÜÂà´Âô®ÂàùÂßãÂåñÂÆåÊàêÔºàÈü≥È¢ëÊµÅÊµãËØïÊ®°ÂºèÔºâ")
        } else {
            // ÁúüÂÆûÊ®°ÂºèÔºöÂàõÂª∫SherpaËØÜÂà´Âô®
            addLog("üîß ÁúüÂÆûÊ®°ÂºèÔºöÂàõÂª∫SherpaËØÜÂà´Âô®...")
            RecordingState.shared.updateInitializationProgress("Ê≠£Âú®È™åËØÅÊ®°ÂûãÊñá‰ª∂...")
            
            // Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            addLog("üìÇ Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂...")
            addLog("  - ÁºñÁ†ÅÂô®: \(encoderPath)")
            addLog("  - Ëß£Á†ÅÂô®: \(decoderPath)")
            addLog("  - ËØçÊ±áË°®: \(tokensPath)")
            
            guard FileManager.default.fileExists(atPath: encoderPath),
                  FileManager.default.fileExists(atPath: decoderPath),
                  FileManager.default.fileExists(atPath: tokensPath) else {
                addLog("‚ùå Ê®°ÂûãÊñá‰ª∂‰∏çÂÆåÊï¥")
                RecordingState.shared.updateInitializationProgress("Ê®°ÂûãÊñá‰ª∂‰∏çÂÆåÊï¥")
                return
            }
            
            // Use helper functions to create configuration
            let paraformerConfig = sherpaOnnxOnlineParaformerModelConfig(
                encoder: encoderPath,
                decoder: decoderPath
            )
            
            let modelConfig = sherpaOnnxOnlineModelConfig(
                tokens: tokensPath,
                paraformer: paraformerConfig,
                numThreads: 2,
                provider: "cpu",
                debug: false,
                modelType: "paraformer",
                modelingUnit: "char"
            )
            
            let featConfig = sherpaOnnxFeatureConfig(
                sampleRate: Int(sampleRate),
                featureDim: 80
            )
            
            var config = sherpaOnnxOnlineRecognizerConfig(
                featConfig: featConfig,
                modelConfig: modelConfig,
                decodingMethod: "greedy_search",
                maxActivePaths: 4,
                enableEndpoint: true,
                rule1MinTrailingSilence: 2.4,
                rule2MinTrailingSilence: 1.2,
                rule3MinUtteranceLength: 20.0
            )
            
            addLog("‚öôÔ∏è ÂàõÂª∫ËØÜÂà´Âô®ÂÆû‰æã...")
            RecordingState.shared.updateInitializationProgress("Ê≠£Âú®ÂàõÂª∫ËØÜÂà´Âô®...")
            recognizer = SherpaOnnxCreateOnlineRecognizer(&config)
            
            if recognizer != nil {
                addLog("‚úÖ ËØÜÂà´Âô®ÂàõÂª∫ÊàêÂäü")
                
                // Create stream
                addLog("üåä ÂàõÂª∫Èü≥È¢ëÊµÅ...")
                RecordingState.shared.updateInitializationProgress("Ê≠£Âú®ÂàõÂª∫Èü≥È¢ëÊµÅ...")
                stream = SherpaOnnxCreateOnlineStream(recognizer)
                
                if stream != nil {
                    addLog("‚úÖ Èü≥È¢ëÊµÅÂàõÂª∫ÊàêÂäü")
                    RecordingState.shared.updateInitializationProgress("ÂàùÂßãÂåñÂÆåÊàê")
                } else {
                    addLog("‚ùå Èü≥È¢ëÊµÅÂàõÂª∫Â§±Ë¥•")
                    RecordingState.shared.updateInitializationProgress("Èü≥È¢ëÊµÅÂàõÂª∫Â§±Ë¥•")
                }
            } else {
                addLog("‚ùå ËØÜÂà´Âô®ÂàõÂª∫Â§±Ë¥•")
            }
        }
    }
    
    private func cleanupRecognizer() {
        addLog("üßπ Ê∏ÖÁêÜËØÜÂà´Âô®ËµÑÊ∫ê...")
        
        if isMockMode {
            // Ê®°ÊãüÊ®°ÂºèÔºöÁõ¥Êé•Ê∏ÖÁ©∫ÂºïÁî®Ôºå‰∏çË∞ÉÁî®CÂáΩÊï∞
            recognizer = nil
            stream = nil
            addLog("‚úÖ Ê®°ÊãüËØÜÂà´Âô®ËµÑÊ∫êÂ∑≤Ê∏ÖÁêÜ")
        } else {
            // ÁúüÂÆûÊ®°ÂºèÔºöË∞ÉÁî®Sherpa CÂáΩÊï∞Ê∏ÖÁêÜ
            if let stream = stream {
                SherpaOnnxDestroyOnlineStream(stream)
                self.stream = nil
                addLog("‚úÖ Èü≥È¢ëÊµÅÂ∑≤ÈîÄÊØÅ")
            }
            
            if let recognizer = recognizer {
                SherpaOnnxDestroyOnlineRecognizer(recognizer)
                self.recognizer = nil
                addLog("‚úÖ ËØÜÂà´Âô®Â∑≤ÈîÄÊØÅ")
            }
        }
        
        addLog("‚úÖ ËØÜÂà´Âô®ËµÑÊ∫êÊ∏ÖÁêÜÂÆåÊàê")
    }
    
    private func processAudioDataSafely(_ buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData else {
            addLog("‚ùå Êó†Ê≥ïËé∑ÂèñÈü≥È¢ëÊï∞ÊçÆ")
            return
        }
        
        let frameLength = Int(buffer.frameLength)
        
        if isMockMode {
            // Ê®°ÊãüÊ®°ÂºèÔºöËÆ∞ÂΩïÈü≥È¢ëÂ§ÑÁêÜ‰ΩÜ‰∏çË∞ÉÁî®Sherpa CÂáΩÊï∞
            Self.logCounter += 1
            if Self.logCounter % 50 == 0 {
                let timestamp = DateFormatter.timeFormatter.string(from: Date())
                addLog("üéµ [\(timestamp)] Ê®°ÊãüÂ§ÑÁêÜÈü≥È¢ë: Á¨¨\(Self.logCounter)Â∏ßÔºåÂ§ßÂ∞è: \(frameLength)")
                
                // Ê®°ÊãüËØÜÂà´ÁªìÊûú
                if Self.logCounter % 200 == 0 {
                    let mockResult = "Ê®°ÊãüËØÜÂà´ÁªìÊûú \(Self.logCounter/200)"
                    DispatchQueue.main.async {
                        self.transcript = mockResult
                        self.addLog("üìù Ê®°ÊãüËØÜÂà´ÁªìÊûú: \(mockResult)")
                        // Ê∑ªÂä†Âà∞ËΩ¨ÂΩïÂéÜÂè≤
                        self.addTranscriptEntry(text: mockResult, isPartial: false)
                        self.delegate?.speechRecognitionDidReceivePartialResult(mockResult)
                    }
                }
            }
            return
        }
        
        // ÁúüÂÆûÊ®°ÂºèÔºöÊ£ÄÊü•ËØÜÂà´Âô®ÊòØÂê¶ÂàùÂßãÂåñ
        guard let recognizer = recognizer,
              let stream = stream else {
            // Âè™ËÆ∞ÂΩï‰∏ÄÊ¨°Ë≠¶ÂëäÔºåÈÅøÂÖçÊó•ÂøóËøáÂ§ö
            if Self.logCounter % 1000 == 0 {
                addLog("‚ö†Ô∏è ËØÜÂà´Âô®Êú™ÂàùÂßãÂåñÔºåË∑≥ËøáÈü≥È¢ëÂ§ÑÁêÜ")
            }
            Self.logCounter += 1
            return
        }
        
        let samples = channelData[0]
        
        // Send audio data to sherpa-onnx
        SherpaOnnxOnlineStreamAcceptWaveform(stream, Int32(sampleRate), samples, Int32(frameLength))
        
        // Check if recognizer is ready to decode
        if SherpaOnnxIsOnlineStreamReady(recognizer, stream) == 1 {
            // Decode the audio
            SherpaOnnxDecodeOnlineStream(recognizer, stream)
            
            // Get partial results - ‰ΩøÁî®ÂÆâÂÖ®ÁöÑÊñπÂºèËÆøÈóÆÁªìÊûú
            if let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream) {
                let resultText = getTextFromResult(result)
                
                if !resultText.isEmpty {
                    DispatchQueue.main.async {
                        self.transcript = resultText
                        self.addLog("üìù ÈÉ®ÂàÜËØÜÂà´ÁªìÊûú: \(resultText)")
                        self.delegate?.speechRecognitionDidReceivePartialResult(resultText)
                    }
                }
                
                SherpaOnnxDestroyOnlineRecognizerResult(result)
            }
        }
        
        // Check for endpoint detection
        if SherpaOnnxOnlineStreamIsEndpoint(recognizer, stream) == 1 {
            addLog("üîö Ê£ÄÊµãÂà∞ËØ≠Èü≥Á´ØÁÇπ")
            
            // Get final result
            if let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream) {
                let finalText = getTextFromResult(result)
                
                if !finalText.isEmpty {
                    DispatchQueue.main.async {
                        self.transcript = finalText
                        self.addLog("‚úÖ ÊúÄÁªàËØÜÂà´ÁªìÊûú: \(finalText)")
                        self.delegate?.speechRecognitionDidReceiveFinalResult(finalText)
                    }
                }
                
                SherpaOnnxDestroyOnlineRecognizerResult(result)
            }
            
            // Notify delegate about endpoint
            DispatchQueue.main.async {
                self.delegate?.speechRecognitionDidDetectEndpoint()
            }
            
            // Reset the stream for next utterance
            SherpaOnnxOnlineStreamReset(recognizer, stream)
        }
        
        // Log audio processing (less frequently)
        if frameLength > 0 {
            Self.logCounter += 1
            if Self.logCounter % 100 == 0 { // Log every 100 buffers
                let timestamp = DateFormatter.timeFormatter.string(from: Date())
                DispatchQueue.main.async {
                    self.addLog("üéµ [\(timestamp)] Â∑≤Â§ÑÁêÜ \(Self.logCounter) ‰∏™Èü≥È¢ëÁºìÂÜ≤Âå∫")
                }
            }
        }
    }
    
    private func getTextFromResult(_ result: UnsafePointer<SherpaOnnxOnlineRecognizerResult>) -> String {
        // ÂÆâÂÖ®Âú∞‰ªé C ÁªìÊûÑ‰Ωì‰∏≠ËØªÂèñÊñáÊú¨
        let text = result.pointee.text
        return text != nil ? String(cString: text!) : ""
    }
    
    private func getFinalResult() -> String? {
        guard let recognizer = recognizer,
              let stream = stream else {
            return nil
        }
        
        if let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream) {
            let finalText = getTextFromResult(result)
            SherpaOnnxDestroyOnlineRecognizerResult(result)
            return finalText.isEmpty ? nil : finalText
        }
        
        return nil
    }
}

// MARK: - Extensions

extension DateFormatter {
    static let logFormatter: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss.SSS"
        return formatter
    }()
    
    static let timeFormatter: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss"
        return formatter
    }()
}