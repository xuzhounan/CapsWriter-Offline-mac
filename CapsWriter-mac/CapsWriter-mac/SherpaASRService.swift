import Foundation
import AVFoundation
import Combine

// ç›´æŽ¥ä½¿ç”¨ C API ä¸­çš„ç±»åž‹å®šä¹‰ï¼Œä¸éœ€è¦æ‰‹åŠ¨å®šä¹‰ç»“æž„ä½“

class SherpaASRService: ObservableObject {
    // MARK: - Published Properties
    @Published var logs: [String] = []
    @Published var transcript: String = ""
    @Published var isServiceRunning: Bool = false
    @Published var isRecognizing: Bool = false
    
    // MARK: - Private Properties
    private var audioEngine: AVAudioEngine?
    private var recognizer: SherpaOnnxOnlineRecognizer?
    private var stream: SherpaOnnxOnlineStream?
    private let audioQueue = DispatchQueue(label: "com.capswriter.audio", qos: .userInitiated)
    private static var logCounter = 0
    
    // Audio configuration
    private let sampleRate: Double = 16000
    private let channels: Int = 1
    
    // Model configuration
    private let modelPath: String
    private let tokensPath: String
    private let encoderPath: String
    private let decoderPath: String
    
    // MARK: - Initialization
    init() {
        // Initialize model paths (will be configured based on actual model structure)
        let bundle = Bundle.main
        self.modelPath = bundle.path(forResource: "paraformer-zh-streaming", ofType: nil, inDirectory: "models") ?? ""
        self.tokensPath = "\(modelPath)/tokens.txt"
        self.encoderPath = "\(modelPath)/encoder.onnx"
        self.decoderPath = "\(modelPath)/decoder.onnx"
        
        addLog("ðŸš€ SherpaASRService åˆå§‹åŒ–")
        addLog("ðŸ“ æ¨¡åž‹è·¯å¾„: \(modelPath)")
    }
    
    deinit {
        stopService()
        addLog("ðŸ›‘ SherpaASRService é”€æ¯")
    }
    
    // MARK: - Public Methods
    
    func startService() {
        addLog("ðŸ”„ æ­£åœ¨å¯åŠ¨è¯­éŸ³è¯†åˆ«æœåŠ¡...")
        
        guard !isServiceRunning else {
            addLog("âš ï¸ æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
            return
        }
        
        // Initialize audio engine
        setupAudioEngine()
        
        // Initialize sherpa-onnx recognizer
        initializeRecognizer()
        
        isServiceRunning = true
        addLog("âœ… è¯­éŸ³è¯†åˆ«æœåŠ¡å¯åŠ¨æˆåŠŸ")
    }
    
    func stopService() {
        addLog("ðŸ›‘ æ­£åœ¨åœæ­¢è¯­éŸ³è¯†åˆ«æœåŠ¡...")
        
        // Stop audio engine
        audioEngine?.stop()
        audioEngine = nil
        
        // Cleanup sherpa-onnx resources
        cleanupRecognizer()
        
        isServiceRunning = false
        isRecognizing = false
        addLog("âœ… è¯­éŸ³è¯†åˆ«æœåŠ¡å·²åœæ­¢")
    }
    
    func startRecognition() {
        guard isServiceRunning else {
            addLog("âŒ æœåŠ¡æœªå¯åŠ¨ï¼Œæ— æ³•å¼€å§‹è¯†åˆ«")
            return
        }
        
        guard !isRecognizing else {
            addLog("âš ï¸ è¯†åˆ«å·²åœ¨è¿›è¡Œä¸­")
            return
        }
        
        addLog("ðŸŽ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        isRecognizing = true
        
        do {
            try audioEngine?.start()
            addLog("âœ… éŸ³é¢‘å¼•æ“Žå¯åŠ¨æˆåŠŸ")
        } catch {
            addLog("âŒ éŸ³é¢‘å¼•æ“Žå¯åŠ¨å¤±è´¥: \(error.localizedDescription)")
            isRecognizing = false
        }
    }
    
    func stopRecognition() {
        guard isRecognizing else {
            addLog("âš ï¸ è¯†åˆ«æœªåœ¨è¿›è¡Œä¸­")
            return
        }
        
        addLog("â¹ï¸ åœæ­¢è¯­éŸ³è¯†åˆ«...")
        audioEngine?.stop()
        isRecognizing = false
        
        // Get final result from sherpa-onnx
        if let finalResult = getFinalResult() {
            transcript = finalResult
            addLog("ðŸ“ æœ€ç»ˆè¯†åˆ«ç»“æžœ: \(finalResult)")
        }
        
        addLog("âœ… è¯­éŸ³è¯†åˆ«å·²åœæ­¢")
    }
    
    // MARK: - Private Methods
    
    private func addLog(_ message: String) {
        let timestamp = DateFormatter.logFormatter.string(from: Date())
        let logMessage = "[\(timestamp)] \(message)"
        
        DispatchQueue.main.async {
            self.logs.append(logMessage)
            // Keep only last 100 log entries
            if self.logs.count > 100 {
                self.logs.removeFirst(self.logs.count - 100)
            }
        }
        
        print(logMessage)
    }
    
    private func setupAudioEngine() {
        addLog("ðŸ”§ é…ç½®éŸ³é¢‘å¼•æ“Ž...")
        
        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else {
            addLog("âŒ æ— æ³•åˆ›å»ºéŸ³é¢‘å¼•æ“Ž")
            return
        }
        
        let inputNode = audioEngine.inputNode
        let inputFormat = inputNode.outputFormat(forBus: 0)
        
        // Configure desired format for sherpa-onnx (16kHz, mono, PCM)
        guard let desiredFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: sampleRate,
            channels: AVAudioChannelCount(channels),
            interleaved: false
        ) else {
            addLog("âŒ æ— æ³•åˆ›å»ºéŸ³é¢‘æ ¼å¼")
            return
        }
        
        addLog("ðŸŽµ è¾“å…¥æ ¼å¼: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)å£°é“")
        addLog("ðŸŽµ ç›®æ ‡æ ¼å¼: \(desiredFormat.sampleRate)Hz, \(desiredFormat.channelCount)å£°é“")
        
        // Install audio tap to process audio data
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: desiredFormat) { [weak self] buffer, time in
            self?.processAudioBuffer(buffer)
        }
        
        addLog("âœ… éŸ³é¢‘å¼•æ“Žé…ç½®å®Œæˆ")
    }
    
    private func initializeRecognizer() {
        addLog("ðŸ§  åˆå§‹åŒ– Sherpa-ONNX è¯†åˆ«å™¨...")
        
        // Check if model files exist
        guard FileManager.default.fileExists(atPath: modelPath) else {
            addLog("âŒ æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨: \(modelPath)")
            return
        }
        
        addLog("ðŸ“‚ æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶...")
        addLog("  - ç¼–ç å™¨: \(encoderPath)")
        addLog("  - è§£ç å™¨: \(decoderPath)")
        addLog("  - è¯æ±‡è¡¨: \(tokensPath)")
        
        // Initialize sherpa-onnx configuration using C API structures
        var paraformerConfig = SherpaOnnxOnlineParaformerModelConfig()
        paraformerConfig.encoder = UnsafePointer(strdup(encoderPath))
        paraformerConfig.decoder = UnsafePointer(strdup(decoderPath))
        
        var transducerConfig = SherpaOnnxOnlineTransducerModelConfig()
        transducerConfig.encoder = nil
        transducerConfig.decoder = nil
        transducerConfig.joiner = nil
        
        var zipformerConfig = SherpaOnnxOnlineZipformer2CtcModelConfig()
        zipformerConfig.model = nil
        
        var modelConfig = SherpaOnnxOnlineModelConfig()
        modelConfig.paraformer = paraformerConfig
        modelConfig.transducer = transducerConfig
        modelConfig.zipformer2_ctc = zipformerConfig
        modelConfig.tokens = UnsafePointer(strdup(tokensPath))
        modelConfig.num_threads = 2
        modelConfig.provider = UnsafePointer(strdup("cpu"))
        modelConfig.debug = 0
        modelConfig.model_type = UnsafePointer(strdup("paraformer"))
        modelConfig.modeling_unit = UnsafePointer(strdup("char"))
        modelConfig.bpe_vocab = nil
        modelConfig.tokens_buf = nil
        modelConfig.tokens_buf_size = 0
        
        var featConfig = SherpaOnnxFeatureConfig()
        featConfig.sample_rate = 16000
        featConfig.feature_dim = 80
        
        var ctcConfig = SherpaOnnxOnlineCtcFstDecoderConfig()
        ctcConfig.graph = nil
        ctcConfig.max_active = 3000
        
        var config = SherpaOnnxOnlineRecognizerConfig()
        config.feat_config = featConfig
        config.model_config = modelConfig
        config.decoding_method = UnsafePointer(strdup("greedy_search"))
        config.max_active_paths = 4
        config.enable_endpoint = 1
        config.rule1_min_trailing_silence = 2.4
        config.rule2_min_trailing_silence = 1.2
        config.rule3_min_utterance_length = 20.0
        config.hotwords_file = nil
        config.hotwords_score = 1.5
        config.ctc_fst_decoder_config = ctcConfig
        config.rule_fsts = nil
        config.rule_fars = nil
        
        addLog("âš™ï¸ åˆ›å»ºè¯†åˆ«å™¨å®žä¾‹...")
        recognizer = SherpaOnnxCreateOnlineRecognizer(&config)
        
        if recognizer != nil {
            addLog("âœ… è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ")
            
            // Create stream
            addLog("ðŸŒŠ åˆ›å»ºéŸ³é¢‘æµ...")
            stream = SherpaOnnxCreateOnlineStream(recognizer)
            
            if stream != nil {
                addLog("âœ… éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ")
            } else {
                addLog("âŒ éŸ³é¢‘æµåˆ›å»ºå¤±è´¥")
            }
        } else {
            addLog("âŒ è¯†åˆ«å™¨åˆ›å»ºå¤±è´¥")
        }
        
        // Cleanup allocated strings
        if let encoder = paraformerConfig.encoder {
            free(UnsafeMutableRawPointer(mutating: encoder))
        }
        if let decoder = paraformerConfig.decoder {
            free(UnsafeMutableRawPointer(mutating: decoder))
        }
        if let tokens = modelConfig.tokens {
            free(UnsafeMutableRawPointer(mutating: tokens))
        }
        if let provider = modelConfig.provider {
            free(UnsafeMutableRawPointer(mutating: provider))
        }
        if let modelType = modelConfig.model_type {
            free(UnsafeMutableRawPointer(mutating: modelType))
        }
        if let modelingUnit = modelConfig.modeling_unit {
            free(UnsafeMutableRawPointer(mutating: modelingUnit))
        }
        if let decodingMethod = config.decoding_method {
            free(UnsafeMutableRawPointer(mutating: decodingMethod))
        }
    }
    
    private func cleanupRecognizer() {
        addLog("ðŸ§¹ æ¸…ç†è¯†åˆ«å™¨èµ„æº...")
        
        if let stream = stream {
            SherpaOnnxDestroyOnlineStream(stream)
            self.stream = nil
            addLog("âœ… éŸ³é¢‘æµå·²é”€æ¯")
        }
        
        if let recognizer = recognizer {
            SherpaOnnxDestroyOnlineRecognizer(recognizer)
            self.recognizer = nil
            addLog("âœ… è¯†åˆ«å™¨å·²é”€æ¯")
        }
        
        addLog("âœ… è¯†åˆ«å™¨èµ„æºæ¸…ç†å®Œæˆ")
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard isRecognizing else { return }
        
        // Process audio data in background queue
        audioQueue.async { [weak self] in
            self?.processAudioData(buffer)
        }
    }
    
    private func processAudioData(_ buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData,
              let recognizer = recognizer,
              let stream = stream else {
            addLog("âŒ æ— æ³•èŽ·å–éŸ³é¢‘æ•°æ®æˆ–è¯†åˆ«å™¨æœªåˆå§‹åŒ–")
            return
        }
        
        let frameLength = Int(buffer.frameLength)
        let samples = channelData[0]
        
        // Send audio data to sherpa-onnx
        SherpaOnnxOnlineStreamAcceptWaveform(stream, Int32(sampleRate), samples, Int32(frameLength))
        
        // Check if recognizer is ready to decode
        if SherpaOnnxIsOnlineStreamReady(recognizer, stream) == 1 {
            // Decode the audio
            SherpaOnnxDecodeOnlineStream(recognizer, stream)
            
            // Get partial results
            let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream)
            if let result = result {
                let textPtr = result.pointee.text
                let resultText = textPtr != nil ? String(cString: textPtr!) : ""
                
                if !resultText.isEmpty {
                    DispatchQueue.main.async {
                        self.transcript = resultText
                        self.addLog("ðŸ“ éƒ¨åˆ†è¯†åˆ«ç»“æžœ: \(resultText)")
                    }
                }
                
                SherpaOnnxDestroyOnlineRecognizerResult(result)
            }
        }
        
        // Check for endpoint detection
        if SherpaOnnxOnlineStreamIsEndpoint(recognizer, stream) == 1 {
            addLog("ðŸ”š æ£€æµ‹åˆ°è¯­éŸ³ç«¯ç‚¹")
            
            // Get final result
            let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream)
            if let result = result {
                let textPtr = result.pointee.text
                let finalText = textPtr != nil ? String(cString: textPtr!) : ""
                
                if !finalText.isEmpty {
                    DispatchQueue.main.async {
                        self.transcript = finalText
                        self.addLog("âœ… æœ€ç»ˆè¯†åˆ«ç»“æžœ: \(finalText)")
                    }
                }
                
                SherpaOnnxDestroyOnlineRecognizerResult(result)
            }
            
            // Reset the stream for next utterance
            SherpaOnnxOnlineStreamReset(recognizer, stream)
        }
        
        // Log audio processing (less frequently)
        if frameLength > 0 {
            Self.logCounter += 1
            if Self.logCounter % 100 == 0 { // Log every 100 buffers
                let timestamp = DateFormatter.timeFormatter.string(from: Date())
                DispatchQueue.main.async {
                    self.addLog("ðŸŽµ [\(timestamp)] å·²å¤„ç† \(Self.logCounter) ä¸ªéŸ³é¢‘ç¼“å†²åŒº")
                }
            }
        }
    }
    
    private func getFinalResult() -> String? {
        guard let recognizer = recognizer,
              let stream = stream else {
            return nil
        }
        
        let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream)
        if let result = result {
            let textPtr = result.pointee.text
            let finalText = textPtr != nil ? String(cString: textPtr!) : ""
            SherpaOnnxDestroyOnlineRecognizerResult(result)
            return finalText.isEmpty ? nil : finalText
        }
        
        return nil
    }
}

// MARK: - Extensions

extension DateFormatter {
    static let logFormatter: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss.SSS"
        return formatter
    }()
    
    static let timeFormatter: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss"
        return formatter
    }()
}