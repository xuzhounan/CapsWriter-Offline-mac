import Foundation
import AVFoundation
import Combine

// MARK: - Transcript Data Models

struct TranscriptEntry: Identifiable, Equatable {
    let id = UUID()
    let timestamp: Date
    let text: String
    let isPartial: Bool
    
    var formattedTime: String {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss"
        return formatter.string(from: timestamp)
    }
}

// MARK: - Sherpa-ONNX C API Helper Functions

/// ğŸ”’ å®‰å…¨ä¿®å¤ï¼šConvert a String from swift to a `const char*` so that we can pass it to
/// the C language. å¢å¼ºç©ºæŒ‡é’ˆæ£€æŸ¥å’Œè¾“å…¥éªŒè¯
func toCPointer(_ s: String) -> UnsafePointer<Int8>? {
  // ğŸ”’ è¾“å…¥éªŒè¯ï¼šæ£€æŸ¥å­—ç¬¦ä¸²æœ‰æ•ˆæ€§
  guard !s.isEmpty else {
    print("âš ï¸ toCPointer: ç©ºå­—ç¬¦ä¸²è¾“å…¥")
    return nil
  }
  
  // ğŸ”’ é•¿åº¦é™åˆ¶ï¼šé˜²æ­¢è¿‡é•¿å­—ç¬¦ä¸²å¯¼è‡´å†…å­˜é—®é¢˜
  let maxLength = 10000
  guard s.count <= maxLength else {
    print("âš ï¸ toCPointer: å­—ç¬¦ä¸²è¿‡é•¿ (\(s.count) å­—ç¬¦)")
    return nil
  }
  
  // ğŸ”’ å®‰å…¨è½¬æ¢ï¼šç¡®ä¿UTF-8è½¬æ¢æˆåŠŸ
  guard let cs = (s as NSString).utf8String else {
    print("âš ï¸ toCPointer: UTF-8è½¬æ¢å¤±è´¥")
    return nil
  }
  
  return UnsafePointer<Int8>(cs)
}

/// ğŸ”’ å®‰å…¨ä¿®å¤ï¼šReturn an instance of SherpaOnnxOnlineParaformerModelConfig.
/// å¢å¼ºå‚æ•°éªŒè¯å’Œç©ºæŒ‡é’ˆå¤„ç†
func sherpaOnnxOnlineParaformerModelConfig(
  encoder: String = "",
  decoder: String = ""
) -> SherpaOnnxOnlineParaformerModelConfig {
  // ğŸ”’ å‚æ•°éªŒè¯ï¼šå¯¹äºç©ºå‚æ•°ä½¿ç”¨é»˜è®¤å€¼
  let safeEncoder = encoder.isEmpty ? "" : encoder
  let safeDecoder = decoder.isEmpty ? "" : decoder
  
  // ğŸ”’ å®‰å…¨è½¬æ¢ï¼šä½¿ç”¨å®‰å…¨çš„æŒ‡é’ˆè½¬æ¢
  let encoderPtr = toCPointer(safeEncoder) ?? toCPointer("")
  let decoderPtr = toCPointer(safeDecoder) ?? toCPointer("")
  
  return SherpaOnnxOnlineParaformerModelConfig(
    encoder: encoderPtr,
    decoder: decoderPtr
  )
}

/// Return an instance of SherpaOnnxOnlineTransducerModelConfig.
func sherpaOnnxOnlineTransducerModelConfig(
  encoder: String = "",
  decoder: String = "",
  joiner: String = ""
) -> SherpaOnnxOnlineTransducerModelConfig {
  return SherpaOnnxOnlineTransducerModelConfig(
    encoder: toCPointer(encoder),
    decoder: toCPointer(decoder),
    joiner: toCPointer(joiner)
  )
}

/// Return an instance of SherpaOnnxOnlineZipformer2CtcModelConfig.
func sherpaOnnxOnlineZipformer2CtcModelConfig(
  model: String = ""
) -> SherpaOnnxOnlineZipformer2CtcModelConfig {
  return SherpaOnnxOnlineZipformer2CtcModelConfig(
    model: toCPointer(model)
  )
}

/// Return an instance of SherpaOnnxOnlineModelConfig.
func sherpaOnnxOnlineModelConfig(
  tokens: String = "",
  transducer: SherpaOnnxOnlineTransducerModelConfig = sherpaOnnxOnlineTransducerModelConfig(),
  paraformer: SherpaOnnxOnlineParaformerModelConfig = sherpaOnnxOnlineParaformerModelConfig(),
  zipformer2Ctc: SherpaOnnxOnlineZipformer2CtcModelConfig = sherpaOnnxOnlineZipformer2CtcModelConfig(),
  numThreads: Int = 1,
  provider: String = "cpu",
  debug: Bool = false,
  modelType: String = "",
  modelingUnit: String = "",
  bpeVocab: String = ""
) -> SherpaOnnxOnlineModelConfig {
  return SherpaOnnxOnlineModelConfig(
    transducer: transducer,
    paraformer: paraformer,
    zipformer2_ctc: zipformer2Ctc,
    tokens: toCPointer(tokens),
    num_threads: Int32(numThreads),
    provider: toCPointer(provider),
    debug: debug ? 1 : 0,
    model_type: toCPointer(modelType),
    modeling_unit: toCPointer(modelingUnit),
    bpe_vocab: toCPointer(bpeVocab),
    tokens_buf: nil,
    tokens_buf_size: 0
  )
}

/// Return an instance of SherpaOnnxFeatureConfig.
func sherpaOnnxFeatureConfig(
  sampleRate: Int = 16000,
  featureDim: Int = 80
) -> SherpaOnnxFeatureConfig {
  return SherpaOnnxFeatureConfig(
    sample_rate: Int32(sampleRate),
    feature_dim: Int32(featureDim)
  )
}

/// Return an instance of SherpaOnnxOnlineRecognizerConfig.
func sherpaOnnxOnlineRecognizerConfig(
  featConfig: SherpaOnnxFeatureConfig = sherpaOnnxFeatureConfig(),
  modelConfig: SherpaOnnxOnlineModelConfig = sherpaOnnxOnlineModelConfig(),
  decodingMethod: String = "greedy_search",
  maxActivePaths: Int = 4,
  enableEndpoint: Bool = false,
  rule1MinTrailingSilence: Float = 2.4,
  rule2MinTrailingSilence: Float = 1.2,
  rule3MinUtteranceLength: Float = 20.0,
  hotwordsFile: String = "",
  hotwordsScore: Float = 1.5
) -> SherpaOnnxOnlineRecognizerConfig {
  return SherpaOnnxOnlineRecognizerConfig(
    feat_config: featConfig,
    model_config: modelConfig,
    decoding_method: toCPointer(decodingMethod),
    max_active_paths: Int32(maxActivePaths),
    enable_endpoint: enableEndpoint ? 1 : 0,
    rule1_min_trailing_silence: rule1MinTrailingSilence,
    rule2_min_trailing_silence: rule2MinTrailingSilence,
    rule3_min_utterance_length: rule3MinUtteranceLength,
    hotwords_file: toCPointer(hotwordsFile),
    hotwords_score: hotwordsScore,
    ctc_fst_decoder_config: SherpaOnnxOnlineCtcFstDecoderConfig(),
    rule_fsts: nil,
    rule_fars: nil,
    blank_penalty: 0.0,
    hotwords_buf: nil,
    hotwords_buf_size: 0,
    hr: SherpaOnnxHomophoneReplacerConfig()
  )
}

// MARK: - Speech Recognition Delegate Protocol

protocol SpeechRecognitionDelegate: AnyObject {
    func speechRecognitionDidReceivePartialResult(_ text: String)
    func speechRecognitionDidReceiveFinalResult(_ text: String)
    func speechRecognitionDidDetectEndpoint()
    func speechRecognitionDidFailWithError(_ error: Error)
}

/// è¯­éŸ³è¯†åˆ«æœåŠ¡åè®®
protocol SpeechRecognitionServiceProtocol: AnyObject {
    // MARK: - Properties
    var isServiceRunning: Bool { get }
    var isInitialized: Bool { get }
    var partialTranscript: String { get set }
    var delegate: SpeechRecognitionDelegate? { get set }
    
    // MARK: - Methods
    func startService()
    func stopService()
    func startRecognition()
    func stopRecognition()
    func processAudioBuffer(_ buffer: AVAudioPCMBuffer)
    func addTranscriptEntry(text: String, isPartial: Bool)
}

// MARK: - Pure ASR Service Class

class SherpaASRService: ObservableObject, SpeechRecognitionServiceProtocol {
    // MARK: - Published Properties
    @Published var logs: [String] = []
    @Published var transcript: String = ""
    @Published var isServiceRunning: Bool = false
    @Published var isRecognizing: Bool = false
    @Published var isInitialized: Bool = false
    @Published var transcriptHistory: [TranscriptEntry] = []
    @Published var partialTranscript: String = ""
    
    // MARK: - Private Properties
    private var recognizer: OpaquePointer?
    private var stream: OpaquePointer?
    private let processingQueue = DispatchQueue(label: "com.capswriter.speech-recognition", qos: .userInitiated)
    private let cleanupQueue = DispatchQueue(label: "com.capswriter.sherpa-cleanup", qos: .utility)
    private static var logCounter = 0
    
    // Mock mode flag - è®¾ç½®ä¸º false æ¥å¯ç”¨çœŸå®æ¨¡å‹
    private let isMockMode = false
    
    // Configuration manager
    private let configManager = ConfigurationManager.shared
    
    // Audio configuration (now from config manager)
    private var sampleRate: Double {
        return configManager.audio.sampleRate
    }
    
    // Model configuration (now from config manager)
    private var modelPath: String {
        let bundle = Bundle.main
        return bundle.path(forResource: configManager.recognition.modelPath, ofType: nil) ?? configManager.recognition.modelPath
    }
    
    private var tokensPath: String {
        return "\(modelPath)/tokens.txt"
    }
    
    private var encoderPath: String {
        return "\(modelPath)/encoder.onnx"
    }
    
    private var decoderPath: String {
        return "\(modelPath)/decoder.onnx"
    }
    
    // Delegate
    weak var delegate: SpeechRecognitionDelegate?
    
    // MARK: - Initialization
    init() {
        addLog("ğŸ§  SherpaASRService åˆå§‹åŒ–ï¼ˆçº¯è¯†åˆ«æœåŠ¡ï¼‰")
        addLog("ğŸ“ æ¨¡å‹è·¯å¾„: \(modelPath)")
        addLog("âš™ï¸ é…ç½®ä¿¡æ¯:")
        addLog("  - é‡‡æ ·ç‡: \(sampleRate)Hz")
        addLog("  - è¯†åˆ«çº¿ç¨‹: \(configManager.recognition.numThreads)")
        addLog("  - è§£ç æ–¹æ³•: \(configManager.recognition.decodingMethod)")
    }
    
    deinit {
        print("ğŸ›‘ SherpaASRService deinit å¼€å§‹")
        // ä½¿ç”¨ä¸“ç”¨é˜Ÿåˆ—è¿›è¡Œæ¸…ç†ï¼Œé¿å…ä¸»çº¿ç¨‹é˜»å¡
        cleanupQueue.sync {
            self.cleanupRecognizer()
        }
        print("ğŸ›‘ SherpaASRService deinit å®Œæˆ")
    }
    
    // MARK: - Public Methods
    
    func startService() {
        addLog("ğŸ”„ æ­£åœ¨å¯åŠ¨è¯­éŸ³è¯†åˆ«æœåŠ¡...")
        
        guard !isServiceRunning else {
            addLog("âš ï¸ æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
            return
        }
        
        // å¼‚æ­¥åˆå§‹åŒ–è¯†åˆ«å™¨ï¼Œé¿å…é˜»å¡è°ƒç”¨çº¿ç¨‹
        processingQueue.async { [weak self] in
            guard let self = self else { return }
            
            RecordingState.shared.updateInitializationProgress("æ­£åœ¨åˆå§‹åŒ–è¯†åˆ«å™¨...")
            self.initializeRecognizer()
            
            DispatchQueue.main.async {
                // åªæœ‰åˆå§‹åŒ–æˆåŠŸåæ‰æ ‡è®°æœåŠ¡ä¸ºè¿è¡ŒçŠ¶æ€
                if self.isInitialized {
                    self.isServiceRunning = true
                    RecordingState.shared.updateInitializationProgress("è¯†åˆ«å™¨å·²å°±ç»ª")
                    self.addLog("âœ… è¯­éŸ³è¯†åˆ«æœåŠ¡å·²å¯åŠ¨")
                } else {
                    self.isServiceRunning = false
                    RecordingState.shared.updateInitializationProgress("è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")
                    self.addLog("âŒ è¯­éŸ³è¯†åˆ«æœåŠ¡å¯åŠ¨å¤±è´¥")
                }
            }
        }
    }
    
    func stopService() {
        addLog("ğŸ›‘ æ­£åœ¨åœæ­¢è¯­éŸ³è¯†åˆ«æœåŠ¡...")
        
        // ä½¿ç”¨ä¸“ç”¨é˜Ÿåˆ—è¿›è¡Œæ¸…ç†ï¼Œé¿å…é˜»å¡è°ƒç”¨çº¿ç¨‹
        cleanupQueue.async { [weak self] in
            self?.cleanupRecognizer()
        }
        
        isServiceRunning = false
        isRecognizing = false
        isInitialized = false
        addLog("âœ… è¯­éŸ³è¯†åˆ«æœåŠ¡å·²åœæ­¢")
    }
    
    func startRecognition() {
        guard isServiceRunning else {
            addLog("âŒ æœåŠ¡æœªå¯åŠ¨ï¼Œæ— æ³•å¼€å§‹è¯†åˆ«")
            return
        }
        
        guard isInitialized else {
            addLog("â³ è¯†åˆ«å™¨æ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åå†è¯•...")
            // å»¶è¿Ÿé‡è¯•
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                self.startRecognition()
            }
            return
        }
        
        guard !isRecognizing else {
            addLog("âš ï¸ è¯†åˆ«å·²åœ¨è¿›è¡Œä¸­")
            return
        }
        
        addLog("ğŸ§  å¼€å§‹è¯­éŸ³è¯†åˆ«å¤„ç†...")
        
        // ç¡®ä¿è¯†åˆ«å™¨å·²åˆå§‹åŒ–
        guard recognizer != nil && stream != nil else {
            addLog("âŒ è¯†åˆ«å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¼€å§‹è¯†åˆ«")
            return
        }
        
        isRecognizing = true
        
        if isMockMode {
            addLog("ğŸ”„ æ¨¡æ‹Ÿæ¨¡å¼ï¼šè·³è¿‡Sherpaè¯†åˆ«å™¨é‡ç½®")
        } else {
            // åªæœ‰çœŸå®æ¨¡å¼æ‰æ£€æŸ¥å¹¶è°ƒç”¨Sherpa Cå‡½æ•°
            guard let recognizer = self.recognizer else {
                addLog("âŒ recognizer æœªåˆå§‹åŒ–")
                isRecognizing = false
                return
            }
            guard let stream = self.stream else {
                addLog("âŒ stream æœªåˆå§‹åŒ–") 
                isRecognizing = false
                return
            }
            
            // é‡ç½®éŸ³é¢‘æµå‡†å¤‡æ–°çš„è¯†åˆ«ä¼šè¯
            SherpaOnnxOnlineStreamReset(recognizer, stream)
            addLog("ğŸ”„ éŸ³é¢‘æµå·²é‡ç½®ï¼Œå‡†å¤‡æ–°çš„è¯†åˆ«ä¼šè¯")
        }
    }
    
    func stopRecognition() {
        guard isRecognizing else {
            addLog("âš ï¸ è¯†åˆ«æœªåœ¨è¿›è¡Œä¸­")
            return
        }
        
        addLog("â¹ï¸ åœæ­¢è¯­éŸ³è¯†åˆ«å¤„ç†...")
        isRecognizing = false
        
        // Get final result from sherpa-onnx
        if let finalResult = getFinalResult() {
            transcript = finalResult
            addLog("ğŸ“ æœ€ç»ˆè¯†åˆ«ç»“æœ: \(finalResult)")
            delegate?.speechRecognitionDidReceiveFinalResult(finalResult)
        }
        
        addLog("âœ… è¯­éŸ³è¯†åˆ«å¤„ç†å·²åœæ­¢")
    }
    
    // MARK: - Transcript Management
    
    func addTranscriptEntry(text: String, isPartial: Bool) {
        guard !text.isEmpty else { return }
        
        let entry = TranscriptEntry(
            timestamp: Date(),
            text: text,
            isPartial: isPartial
        )
        
        // åœ¨ä¸»çº¿ç¨‹æ›´æ–°UI
        DispatchQueue.main.async {
            self.transcriptHistory.append(entry)
            
            // ä¿æŒå†å²è®°å½•ä¸è¶…è¿‡100æ¡
            if self.transcriptHistory.count > 100 {
                self.transcriptHistory.removeFirst(self.transcriptHistory.count - 100)
            }
        }
        
        addLog("ğŸ“ æ·»åŠ è½¬å½•æ¡ç›®: \(text)")
    }
    
    func clearTranscriptHistory() {
        DispatchQueue.main.async {
            self.transcriptHistory.removeAll()
            self.partialTranscript = ""
        }
        addLog("ğŸ—‘ï¸ è½¬å½•å†å²å·²æ¸…ç©º")
    }
    
    // MARK: - Audio Processing Interface
    
    func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        // æ·»åŠ æ¥æ”¶éŸ³é¢‘ç¼“å†²åŒºçš„è°ƒè¯•æ—¥å¿—ï¼ˆæ¯100å¸§è¾“å‡ºä¸€æ¬¡ï¼‰
        Self.logCounter += 1
        if Self.logCounter % 100 == 0 {
            addLog("ğŸ“¥ ASRæœåŠ¡å·²æ¥æ”¶ \(Self.logCounter) ä¸ªéŸ³é¢‘ç¼“å†²åŒºï¼Œå½“å‰ç¼“å†²åŒºå¤§å°: \(buffer.frameLength)")
        }
        
        guard isRecognizing else { 
            if Self.logCounter % 100 == 0 {
                addLog("âš ï¸ ASRæœåŠ¡æœªåœ¨è¯†åˆ«çŠ¶æ€ï¼Œè·³è¿‡éŸ³é¢‘å¤„ç†")
            }
            return 
        }
        
        // Process audio data in background queue
        processingQueue.async { [weak self] in
            self?.processAudioDataSafely(buffer)
        }
    }
    
    // MARK: - Private Methods
    
    private func addLog(_ message: String) {
        let timestamp = DateFormatter.logFormatter.string(from: Date())
        let logMessage = "[\(timestamp)] \(message)"
        
        DispatchQueue.main.async {
            self.logs.append(logMessage)
            // Keep only last 100 log entries
            if self.logs.count > 100 {
                self.logs.removeFirst(self.logs.count - 100)
            }
        }
        
        print(logMessage)
    }
    
    private func initializeRecognizer() {
        addLog("ğŸ§  åˆå§‹åŒ– Sherpa-ONNX è¯†åˆ«å™¨...")
        RecordingState.shared.updateInitializationProgress("æ­£åœ¨æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
        
        // é‡ç½®åˆå§‹åŒ–çŠ¶æ€
        isInitialized = false
        
        // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        addLog("ğŸ“‚ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
        addLog("  - æ¨¡å‹è·¯å¾„: \(modelPath)")
        addLog("  - ç¼–ç å™¨: \(encoderPath)")
        addLog("  - è§£ç å™¨: \(decoderPath)")
        addLog("  - è¯æ±‡è¡¨: \(tokensPath)")
        
        guard FileManager.default.fileExists(atPath: modelPath) else {
            addLog("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: \(modelPath)")
            addLog("âš ï¸ è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å¤„ç†éŸ³é¢‘")
            RecordingState.shared.updateInitializationProgress("æ¨¡å‹æ–‡ä»¶ç¼ºå¤±")
            return
        }
        
        if isMockMode {
            // æ¨¡æ‹Ÿæ¨¡å¼ï¼šä¸åˆ›å»ºçœŸå®çš„Sherpaå¯¹è±¡ï¼Œä¿æŒnilçŠ¶æ€
            addLog("ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼ï¼šä¸åˆ›å»ºçœŸå®è¯†åˆ«å™¨")
            addLog("âœ… æ¨¡æ‹Ÿè¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆï¼ˆéŸ³é¢‘æµæµ‹è¯•æ¨¡å¼ï¼‰")
            isInitialized = true
        } else {
            // çœŸå®æ¨¡å¼ï¼šåˆ›å»ºSherpaè¯†åˆ«å™¨
            addLog("ğŸ”§ çœŸå®æ¨¡å¼ï¼šåˆ›å»ºSherpaè¯†åˆ«å™¨...")
            RecordingState.shared.updateInitializationProgress("æ­£åœ¨éªŒè¯æ¨¡å‹æ–‡ä»¶...")
            
            // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            addLog("ğŸ“‚ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
            addLog("  - ç¼–ç å™¨: \(encoderPath)")
            addLog("  - è§£ç å™¨: \(decoderPath)")
            addLog("  - è¯æ±‡è¡¨: \(tokensPath)")
            
            guard FileManager.default.fileExists(atPath: encoderPath),
                  FileManager.default.fileExists(atPath: decoderPath),
                  FileManager.default.fileExists(atPath: tokensPath) else {
                addLog("âŒ æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´")
                RecordingState.shared.updateInitializationProgress("æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´")
                return
            }
            
            // Use helper functions to create configuration
            let paraformerConfig = sherpaOnnxOnlineParaformerModelConfig(
                encoder: encoderPath,
                decoder: decoderPath
            )
            
            let modelConfig = sherpaOnnxOnlineModelConfig(
                tokens: tokensPath,
                paraformer: paraformerConfig,
                numThreads: configManager.recognition.numThreads,
                provider: configManager.recognition.provider,
                debug: configManager.recognition.debug,
                modelType: configManager.recognition.modelType,
                modelingUnit: configManager.recognition.modelingUnit
            )
            
            let featConfig = sherpaOnnxFeatureConfig(
                sampleRate: Int(sampleRate),
                featureDim: 80
            )
            
            var config = sherpaOnnxOnlineRecognizerConfig(
                featConfig: featConfig,
                modelConfig: modelConfig,
                decodingMethod: configManager.recognition.decodingMethod,
                maxActivePaths: configManager.recognition.maxActivePaths,
                enableEndpoint: configManager.recognition.enableEndpoint,
                rule1MinTrailingSilence: configManager.recognition.rule1MinTrailingSilence,
                rule2MinTrailingSilence: configManager.recognition.rule2MinTrailingSilence,
                rule3MinUtteranceLength: configManager.recognition.rule3MinUtteranceLength
            )
            
            addLog("âš™ï¸ åˆ›å»ºè¯†åˆ«å™¨å®ä¾‹...")
            RecordingState.shared.updateInitializationProgress("æ­£åœ¨åˆ›å»ºè¯†åˆ«å™¨...")
            // ğŸ”’ å®‰å…¨ä¿®å¤ï¼šå®‰å…¨åˆ›å»ºè¯†åˆ«å™¨ï¼Œå¢å¼ºé”™è¯¯å¤„ç†
            recognizer = SherpaOnnxCreateOnlineRecognizer(&config)
            
            // ğŸ”’ ç©ºæŒ‡é’ˆæ£€æŸ¥ï¼šç¡®ä¿è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ
            guard let validRecognizer = recognizer else {
                addLog("âŒ è¯†åˆ«å™¨åˆ›å»ºå¤±è´¥ï¼šè¿”å›ç©ºæŒ‡é’ˆ")
                RecordingState.shared.updateInitializationProgress("è¯†åˆ«å™¨åˆ›å»ºå¤±è´¥")
                isInitialized = false
                return
            }
            
            addLog("âœ… è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ")
            
            // ğŸ”’ å®‰å…¨åˆ›å»ºéŸ³é¢‘æµ
            addLog("ğŸŒŠ åˆ›å»ºéŸ³é¢‘æµ...")
            RecordingState.shared.updateInitializationProgress("æ­£åœ¨åˆ›å»ºéŸ³é¢‘æµ...")
            
            stream = SherpaOnnxCreateOnlineStream(validRecognizer)
            
            // ğŸ”’ ç©ºæŒ‡é’ˆæ£€æŸ¥ï¼šç¡®ä¿éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ
            guard stream != nil else {
                addLog("âŒ éŸ³é¢‘æµåˆ›å»ºå¤±è´¥ï¼šè¿”å›ç©ºæŒ‡é’ˆ")
                RecordingState.shared.updateInitializationProgress("éŸ³é¢‘æµåˆ›å»ºå¤±è´¥")
                
                // ğŸ”’ èµ„æºæ¸…ç†ï¼šæ¸…ç†å·²åˆ›å»ºçš„è¯†åˆ«å™¨
                SherpaOnnxDestroyOnlineRecognizer(validRecognizer)
                recognizer = nil
                isInitialized = false
                return
            }
            
            addLog("âœ… éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ")
            RecordingState.shared.updateInitializationProgress("åˆå§‹åŒ–å®Œæˆ")
            isInitialized = true
        }
    }
    
    private func cleanupRecognizer() {
        addLog("ğŸ§¹ æ¸…ç†è¯†åˆ«å™¨èµ„æº...")
        
        if isMockMode {
            // æ¨¡æ‹Ÿæ¨¡å¼ï¼šç›´æ¥æ¸…ç©ºå¼•ç”¨ï¼Œä¸è°ƒç”¨Cå‡½æ•°
            recognizer = nil
            stream = nil
            addLog("âœ… æ¨¡æ‹Ÿè¯†åˆ«å™¨èµ„æºå·²æ¸…ç†")
        } else {
            // çœŸå®æ¨¡å¼ï¼šè°ƒç”¨Sherpa Cå‡½æ•°æ¸…ç†
            if let stream = stream {
                SherpaOnnxDestroyOnlineStream(stream)
                self.stream = nil
                addLog("âœ… éŸ³é¢‘æµå·²é”€æ¯")
            }
            
            if let recognizer = recognizer {
                SherpaOnnxDestroyOnlineRecognizer(recognizer)
                self.recognizer = nil
                addLog("âœ… è¯†åˆ«å™¨å·²é”€æ¯")
            }
        }
        
        addLog("âœ… è¯†åˆ«å™¨èµ„æºæ¸…ç†å®Œæˆ")
    }
    
    private func processAudioDataSafely(_ buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData else {
            addLog("âŒ æ— æ³•è·å–éŸ³é¢‘æ•°æ®")
            return
        }
        
        let frameLength = Int(buffer.frameLength)
        
        if isMockMode {
            // æ¨¡æ‹Ÿæ¨¡å¼ï¼šè®°å½•éŸ³é¢‘å¤„ç†ä½†ä¸è°ƒç”¨Sherpa Cå‡½æ•°
            Self.logCounter += 1
            if Self.logCounter % 50 == 0 {
                let timestamp = DateFormatter.timeFormatter.string(from: Date())
                addLog("ğŸµ [\(timestamp)] æ¨¡æ‹Ÿå¤„ç†éŸ³é¢‘: ç¬¬\(Self.logCounter)å¸§ï¼Œå¤§å°: \(frameLength)")
                
                // æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
                if Self.logCounter % 200 == 0 {
                    let mockResult = "æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ \(Self.logCounter/200)"
                    DispatchQueue.main.async {
                        self.transcript = mockResult
                        self.addLog("ğŸ“ æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ: \(mockResult)")
                        // æ·»åŠ åˆ°è½¬å½•å†å²
                        self.addTranscriptEntry(text: mockResult, isPartial: false)
                        self.delegate?.speechRecognitionDidReceivePartialResult(mockResult)
                    }
                }
            }
            return
        }
        
        // ğŸ”’ å®‰å…¨ä¿®å¤ï¼šæ£€æŸ¥è¯†åˆ«å™¨æ˜¯å¦åˆå§‹åŒ–
        guard let recognizer = recognizer,
              let stream = stream else {
            // åªè®°å½•ä¸€æ¬¡è­¦å‘Šï¼Œé¿å…æ—¥å¿—è¿‡å¤š
            if Self.logCounter % 1000 == 0 {
                addLog("âš ï¸ è¯†åˆ«å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡éŸ³é¢‘å¤„ç†")
            }
            Self.logCounter += 1
            return
        }
        
        // ğŸ”’ å®‰å…¨éªŒè¯ï¼šæ£€æŸ¥éŸ³é¢‘æ•°æ®æœ‰æ•ˆæ€§
        guard frameLength > 0 else {
            addLog("âš ï¸ éŸ³é¢‘å¸§é•¿åº¦æ— æ•ˆ: \(frameLength)")
            return
        }
        
        let maxFrameLength = 1024 * 1024  // 1M samples é™åˆ¶
        guard frameLength <= maxFrameLength else {
            addLog("âš ï¸ éŸ³é¢‘å¸§é•¿åº¦è¿‡å¤§: \(frameLength)")
            return
        }
        
        // ğŸ”’ å®‰å…¨è·å–éŸ³é¢‘æ ·æœ¬
        let samples = channelData[0]
        
        // ğŸ”’ å®‰å…¨è°ƒç”¨ï¼šSend audio data to sherpa-onnx
        // samples æ˜¯éå¯é€‰çš„æŒ‡é’ˆï¼Œç›´æ¥ä½¿ç”¨
        SherpaOnnxOnlineStreamAcceptWaveform(stream, Int32(sampleRate), samples, Int32(frameLength))
        
        // ğŸ”’ å®‰å…¨æ£€æŸ¥ï¼šæ£€æŸ¥è¯†åˆ«å™¨æ˜¯å¦å‡†å¤‡å¥½è§£ç 
        let isReady = SherpaOnnxIsOnlineStreamReady(recognizer, stream)
        if isReady == 1 {
            // ğŸ”’ å®‰å…¨è§£ç ï¼šDecode the audio
            SherpaOnnxDecodeOnlineStream(recognizer, stream)
            
            // ğŸ”’ å®‰å…¨è·å–ç»“æœï¼šæ£€æŸ¥ç»“æœæŒ‡é’ˆæœ‰æ•ˆæ€§
            if let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream) {
                // ğŸ”’ å®‰å…¨æ–‡æœ¬æå–ï¼šä½¿ç”¨å®‰å…¨æ–¹æ³•æå–æ–‡æœ¬
                let resultText = getTextFromResultSafely(result)
                
                if !resultText.isEmpty {
                    DispatchQueue.main.async {
                        self.transcript = resultText
                        self.addLog("ğŸ“ éƒ¨åˆ†è¯†åˆ«ç»“æœ: \(resultText)")
                        self.delegate?.speechRecognitionDidReceivePartialResult(resultText)
                    }
                }
                
                // ğŸ”’ èµ„æºæ¸…ç†ï¼šç¡®ä¿ç»“æœè¢«æ­£ç¡®é‡Šæ”¾
                SherpaOnnxDestroyOnlineRecognizerResult(result)
            }
        }
        
        // Check for endpoint detection
        if SherpaOnnxOnlineStreamIsEndpoint(recognizer, stream) == 1 {
            addLog("ğŸ”š æ£€æµ‹åˆ°è¯­éŸ³ç«¯ç‚¹")
            
            // Get final result
            if let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream) {
                let finalText = getTextFromResult(result)
                
                if !finalText.isEmpty {
                    DispatchQueue.main.async {
                        self.transcript = finalText
                        self.addLog("âœ… æœ€ç»ˆè¯†åˆ«ç»“æœ: \(finalText)")
                        self.delegate?.speechRecognitionDidReceiveFinalResult(finalText)
                    }
                }
                
                SherpaOnnxDestroyOnlineRecognizerResult(result)
            }
            
            // Notify delegate about endpoint
            DispatchQueue.main.async {
                self.delegate?.speechRecognitionDidDetectEndpoint()
            }
            
            // Reset the stream for next utterance
            SherpaOnnxOnlineStreamReset(recognizer, stream)
        }
        
        // Log audio processing (less frequently)
        if frameLength > 0 {
            Self.logCounter += 1
            if Self.logCounter % 100 == 0 { // Log every 100 buffers
                let timestamp = DateFormatter.timeFormatter.string(from: Date())
                DispatchQueue.main.async {
                    self.addLog("ğŸµ [\(timestamp)] å·²å¤„ç† \(Self.logCounter) ä¸ªéŸ³é¢‘ç¼“å†²åŒº")
                }
            }
        }
    }
    
    // ğŸ”’ å®‰å…¨ä¿®å¤ï¼šå®‰å…¨åœ°ä» C ç»“æ„ä½“ä¸­è¯»å–æ–‡æœ¬
    private func getTextFromResult(_ result: UnsafePointer<SherpaOnnxOnlineRecognizerResult>) -> String {
        return getTextFromResultSafely(result)
    }
    
    // ğŸ”’ å®‰å…¨æ–¹æ³•ï¼šå¢å¼ºç‰ˆæœ¬çš„æ–‡æœ¬æå–
    private func getTextFromResultSafely(_ result: UnsafePointer<SherpaOnnxOnlineRecognizerResult>) -> String {
        // ğŸ”’ ç©ºæŒ‡é’ˆæ£€æŸ¥ï¼šç¡®ä¿resultæŒ‡é’ˆæœ‰æ•ˆ
        // result æ˜¯éå¯é€‰çš„æŒ‡é’ˆå‚æ•°ï¼Œä¸éœ€è¦æ£€æŸ¥æ˜¯å¦ä¸º nil
        
        // ğŸ”’ ç»“æ„ä½“è®¿é—®ï¼šå®‰å…¨è®¿é—®ç»“æ„ä½“æˆå‘˜
        let textPointer = result.pointee.text
        
        // ğŸ”’ æ–‡æœ¬æŒ‡é’ˆæ£€æŸ¥ï¼šç¡®ä¿textæŒ‡é’ˆæœ‰æ•ˆ
        guard let validTextPointer = textPointer else {
            print("âš ï¸ getTextFromResultSafely: textæŒ‡é’ˆæ— æ•ˆ")
            return ""
        }
        
        // ğŸ”’ é•¿åº¦æ£€æŸ¥ï¼šé˜²æ­¢è¿‡é•¿çš„æ–‡æœ¬å¯¼è‡´å†…å­˜é—®é¢˜
        let maxTextLength = 10000
        let textLength = strlen(validTextPointer)
        
        guard textLength <= maxTextLength else {
            print("âš ï¸ getTextFromResultSafely: æ–‡æœ¬è¿‡é•¿ (\(textLength) å­—ç¬¦)")
            // è¿”å›æˆªæ–­çš„æ–‡æœ¬
            let truncatedData = Data(bytes: validTextPointer, count: min(Int(textLength), maxTextLength))
            return String(data: truncatedData, encoding: .utf8) ?? ""
        }
        
        // ğŸ”’ å®‰å…¨è½¬æ¢ï¼šä½¿ç”¨å®‰å…¨çš„å­—ç¬¦ä¸²åˆ›å»ºæ–¹æ³•
        let resultString = String(cString: validTextPointer)
        
        // ğŸ”’ å†…å®¹éªŒè¯ï¼šæ£€æŸ¥æ–‡æœ¬å†…å®¹åˆç†æ€§
        guard !resultString.isEmpty else {
            return ""
        }
        
        // ğŸ”’ å­—ç¬¦éªŒè¯ï¼šç§»é™¤æ½œåœ¨çš„æ§åˆ¶å­—ç¬¦
        let cleanedString = resultString.filter { $0.isASCII || $0.unicodeScalars.allSatisfy(CharacterSet.alphanumerics.union(.punctuationCharacters).union(.whitespaces).contains) }
        
        return cleanedString
    }
    
    private func getFinalResult() -> String? {
        guard let recognizer = recognizer,
              let stream = stream else {
            return nil
        }
        
        if let result = SherpaOnnxGetOnlineStreamResult(recognizer, stream) {
            let finalText = getTextFromResult(result)
            SherpaOnnxDestroyOnlineRecognizerResult(result)
            return finalText.isEmpty ? nil : finalText
        }
        
        return nil
    }
}

// MARK: - Extensions

extension DateFormatter {
    static let logFormatter: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss.SSS"
        return formatter
    }()
    
    static let timeFormatter: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss"
        return formatter
    }()
}