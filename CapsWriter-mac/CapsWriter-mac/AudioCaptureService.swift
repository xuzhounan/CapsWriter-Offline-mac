import Foundation
import AVFoundation
import Combine

protocol AudioCaptureDelegate: AnyObject {
    func audioCaptureDidReceiveBuffer(_ buffer: AVAudioPCMBuffer)
    func audioCaptureDidStart()
    func audioCaptureDidStop()
    func audioCaptureDidFailWithError(_ error: Error)
}

/// éŸ³é¢‘é‡‡é›†æœåŠ¡åè®®
protocol AudioCaptureServiceProtocol: AnyObject {
    // MARK: - Properties
    var isCapturing: Bool { get }
    var hasPermission: Bool { get }
    var delegate: AudioCaptureDelegate? { get set }
    
    // MARK: - Methods
    func checkMicrophonePermission() -> Bool
    func requestPermissionAndStartCapture()
    func startCapture()
    func stopCapture()
}

class AudioCaptureService: ObservableObject, AudioCaptureServiceProtocol {
    // MARK: - Published Properties
    @Published var isCapturing: Bool = false
    @Published var hasPermission: Bool = false
    @Published var logs: [String] = []
    
    // MARK: - Private Properties
    private var audioEngine: AVAudioEngine?
    private let audioQueue = DispatchQueue(label: "com.capswriter.audio-capture", qos: .userInitiated)
    
    // Configuration manager
    private let configManager = ConfigurationManager.shared
    
    // Audio configuration (now from config manager)
    private var sampleRate: Double {
        return configManager.audio.sampleRate
    }
    
    private var channels: Int {
        return configManager.audio.channels
    }
    
    private var bufferSize: UInt32 {
        return configManager.audio.bufferSize
    }
    
    // Audio processing counter
    private static var bufferCount = 0
    
    // Delegate
    weak var delegate: AudioCaptureDelegate?
    
    // MARK: - Initialization
    init() {
        addLog("ğŸ¤ AudioCaptureService åˆå§‹åŒ–")
        addLog("âš™ï¸ éŸ³é¢‘é…ç½®: \(sampleRate)Hz, \(channels)å£°é“, ç¼“å†²åŒº \(bufferSize)")
        // ä¸åœ¨åˆå§‹åŒ–æ—¶æ£€æŸ¥æƒé™ï¼Œé¿å…è§¦å‘ TCC è®¿é—®
        // æƒé™æ£€æŸ¥å°†åœ¨å®é™…éœ€è¦æ—¶è¿›è¡Œ
    }
    
    deinit {
        stopCapture()
        addLog("ğŸ›‘ AudioCaptureService é”€æ¯")
    }
    
    // MARK: - Public Methods
    
    /// æ£€æŸ¥éº¦å…‹é£æƒé™
    func checkMicrophonePermission() -> Bool {
        let status = AVAudioApplication.shared.recordPermission
        return status == .granted
    }
    
    /// ä»…è¯·æ±‚æƒé™ï¼Œä¸å¯åŠ¨é‡‡é›†
    func requestPermissionOnly(completion: @escaping (Bool) -> Void) {
        addLog("ğŸ” ä»…è¯·æ±‚éº¦å…‹é£æƒé™ï¼ˆä¸å¯åŠ¨é‡‡é›†ï¼‰...")
        
        // ç¡®ä¿åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œ
        DispatchQueue.main.async { [weak self] in
            self?.checkAndRequestPermission(completion: completion)
        }
    }
    
    func requestPermissionAndStartCapture() {
        addLog("ğŸ” è¯·æ±‚éº¦å…‹é£æƒé™...")
        
        // ç¡®ä¿åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œ
        DispatchQueue.main.async { [weak self] in
            self?.checkAndRequestPermission { [weak self] success in
                if success {
                    self?.addLog("âœ… æƒé™è·å–æˆåŠŸï¼Œç°åœ¨å¼€å§‹é‡‡é›†")
                    // å»¶è¿Ÿä¸€ç‚¹ç¡®ä¿éŸ³é¢‘è®¾å¤‡å®Œå…¨å‡†å¤‡å¥½
                    DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                        self?.startCapture()
                    }
                } else {
                    self?.addLog("âŒ æƒé™è·å–å¤±è´¥ï¼Œæ— æ³•å¼€å§‹é‡‡é›†")
                }
            }
        }
    }
    
    private func checkAndRequestPermission(completion: @escaping (Bool) -> Void) {
        addLog("ğŸ” æ£€æŸ¥å½“å‰éº¦å…‹é£æƒé™çŠ¶æ€...")
        
        let currentStatus = AVCaptureDevice.authorizationStatus(for: .audio)
        addLog("ğŸ¤ å½“å‰æƒé™çŠ¶æ€: \(audioPermissionStatusString(currentStatus))")
        
        switch currentStatus {
        case .authorized:
            addLog("âœ… æƒé™å·²æˆæƒ")
            self.hasPermission = true
            completion(true)
            
        case .notDetermined:
            addLog("ğŸ” æƒé™æœªç¡®å®šï¼Œè¯·æ±‚æƒé™...")
            AVCaptureDevice.requestAccess(for: .audio) { [weak self] granted in
                DispatchQueue.main.async {
                    self?.addLog("ğŸ¤ æƒé™è¯·æ±‚å®Œæˆ: \(granted ? "å·²æˆæƒ" : "è¢«æ‹’ç»")")
                    if granted {
                        self?.hasPermission = true
                        completion(true)
                    } else {
                        self?.hasPermission = false
                        self?.addLog("âŒ ç”¨æˆ·æ‹’ç»äº†éº¦å…‹é£æƒé™")
                        completion(false)
                    }
                }
            }
            
        case .denied, .restricted:
            addLog("âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»æˆ–å—é™")
            self.hasPermission = false
            completion(false)
            
        @unknown default:
            addLog("â“ æœªçŸ¥éº¦å…‹é£æƒé™çŠ¶æ€")
            self.hasPermission = false
            completion(false)
        }
    }
    
    private func audioPermissionStatusString(_ status: AVAuthorizationStatus) -> String {
        switch status {
        case .authorized: return "å·²æˆæƒ"
        case .denied: return "å·²æ‹’ç»"
        case .restricted: return "å—é™åˆ¶"
        case .notDetermined: return "æœªç¡®å®š"
        @unknown default: return "æœªçŸ¥çŠ¶æ€"
        }
    }
    
    func startCapture() {
        addLog("ğŸ¤ å¼€å§‹éŸ³é¢‘é‡‡é›†...")
        
        guard hasPermission else {
            addLog("âŒ æ²¡æœ‰éº¦å…‹é£æƒé™ï¼Œæ— æ³•å¼€å§‹é‡‡é›†")
            delegate?.audioCaptureDidFailWithError(AudioCaptureError.permissionDenied)
            return
        }
        
        guard !isCapturing else {
            addLog("âš ï¸ éŸ³é¢‘é‡‡é›†å·²åœ¨è¿›è¡Œä¸­")
            return
        }
        
        // åœ¨éŸ³é¢‘é˜Ÿåˆ—ä¸­è®¾ç½®å’Œå¯åŠ¨éŸ³é¢‘å¼•æ“
        audioQueue.async { [weak self] in
            self?.setupAndStartAudioEngine()
        }
    }
    
    private func setupAndStartAudioEngine() {
        addLog("ğŸ§ åœ¨éŸ³é¢‘é˜Ÿåˆ—ä¸­è®¾ç½®éŸ³é¢‘å¼•æ“...")
        
        do {
            try setupAudioEngine()
            
            guard let audioEngine = self.audioEngine else {
                DispatchQueue.main.async {
                    self.addLog("âŒ éŸ³é¢‘å¼•æ“åˆ›å»ºå¤±è´¥")
                    self.delegate?.audioCaptureDidFailWithError(AudioCaptureError.engineSetupFailed)
                }
                return
            }
            
            addLog("ğŸš€ å°è¯•å¯åŠ¨éŸ³é¢‘å¼•æ“...")
            try audioEngine.start()
            
            DispatchQueue.main.async {
                self.isCapturing = true
                self.addLog("âœ… éŸ³é¢‘é‡‡é›†å¯åŠ¨æˆåŠŸ")
                self.delegate?.audioCaptureDidStart()
            }
            
        } catch {
            DispatchQueue.main.async {
                self.addLog("âŒ éŸ³é¢‘é‡‡é›†å¯åŠ¨å¤±è´¥: \(error.localizedDescription)")
                self.addLog("âŒ é”™è¯¯è¯¦æƒ…: \(error)")
                self.isCapturing = false
                self.delegate?.audioCaptureDidFailWithError(error)
            }
        }
    }
    
    func stopCapture() {
        guard isCapturing else {
            addLog("âš ï¸ éŸ³é¢‘é‡‡é›†æœªåœ¨è¿›è¡Œä¸­")
            return
        }
        
        addLog("â¹ï¸ åœæ­¢éŸ³é¢‘é‡‡é›†...")
        
        // åœ¨éŸ³é¢‘é˜Ÿåˆ—ä¸­åœæ­¢éŸ³é¢‘å¼•æ“
        audioQueue.async { [weak self] in
            self?.stopAudioEngine()
        }
    }
    
    private func stopAudioEngine() {
        if let audioEngine = audioEngine {
            audioEngine.stop()
            cleanupAudioEngine()
        }
        
        DispatchQueue.main.async {
            self.isCapturing = false
            self.addLog("âœ… éŸ³é¢‘é‡‡é›†å·²åœæ­¢")
            self.delegate?.audioCaptureDidStop()
        }
    }
    
    // MARK: - Audio Engine Setup
    
    private func setupAudioEngine() throws {
        addLog("ğŸ”§ é…ç½®éŸ³é¢‘å¼•æ“...")
        
        // æ¸…ç†ä¹‹å‰çš„éŸ³é¢‘å¼•æ“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        cleanupAudioEngine()
        
        addLog("ğŸ—ï¸ åˆ›å»ºæ–°çš„ AVAudioEngine...")
        audioEngine = AVAudioEngine()
        
        guard let audioEngine = audioEngine else {
            throw AudioCaptureError.engineSetupFailed
        }
        
        addLog("ğŸ¤ è·å–éŸ³é¢‘è¾“å…¥èŠ‚ç‚¹...")
        let inputNode = audioEngine.inputNode
        let inputFormat = inputNode.outputFormat(forBus: 0)
        
        addLog("ğŸµ åŸå§‹è¾“å…¥æ ¼å¼: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)å£°é“")
        
        // Configure desired format for speech recognition (16kHz, mono, PCM)
        guard let desiredFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: sampleRate,
            channels: AVAudioChannelCount(channels),
            interleaved: false
        ) else {
            addLog("âŒ æ— æ³•åˆ›å»ºéŸ³é¢‘æ ¼å¼")
            throw AudioCaptureError.engineSetupFailed
        }
        
        addLog("ğŸµ ç›®æ ‡æ ¼å¼: \(desiredFormat.sampleRate)Hz, \(desiredFormat.channelCount)å£°é“")
        
        addLog("ğŸ§¹ ç§»é™¤å·²å­˜åœ¨çš„ tap...")
        inputNode.removeTap(onBus: 0)
        
        addLog("ğŸ”Œ å®‰è£…éŸ³é¢‘ tap...")
        // ä½¿ç”¨ç¡¬ä»¶çš„åŸå§‹æ ¼å¼å®‰è£…tapï¼Œé¿å…æ ¼å¼ä¸åŒ¹é…é”™è¯¯
        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, time in
            // åœ¨è¿™é‡Œè¿›è¡Œæ ¼å¼è½¬æ¢å¹¶å¤„ç†
            self?.processAudioBuffer(buffer, targetFormat: desiredFormat)
        }
        
        addLog("âš™ï¸ é¢„å¤‡éŸ³é¢‘å¼•æ“...")
        audioEngine.prepare()
        addLog("âœ… éŸ³é¢‘å¼•æ“é¢„å¤‡æˆåŠŸ")
        
        addLog("âœ… éŸ³é¢‘å¼•æ“é…ç½®å®Œæˆ")
    }
    
    private func cleanupAudioEngine() {
        addLog("ğŸ§¹ æ¸…ç†éŸ³é¢‘å¼•æ“...")
        
        if let audioEngine = audioEngine {
            // å®‰å…¨åœ°ç§»é™¤ tap
            audioEngine.inputNode.removeTap(onBus: 0)
            
            // åœæ­¢éŸ³é¢‘å¼•æ“
            if audioEngine.isRunning {
                audioEngine.stop()
            }
            
            addLog("âœ… éŸ³é¢‘å¼•æ“å·²åœæ­¢")
        }
        
        audioEngine = nil
        addLog("âœ… éŸ³é¢‘å¼•æ“æ¸…ç†å®Œæˆ")
    }
    
    // MARK: - Audio Processing
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, targetFormat: AVAudioFormat) {
        guard isCapturing else { return }
        
        // æ·»åŠ éŸ³é¢‘æ•°æ®æ—¥å¿—ï¼ˆæ¯100å¸§è¾“å‡ºä¸€æ¬¡é¿å…åˆ·å±ï¼‰
        AudioCaptureService.bufferCount += 1
        if AudioCaptureService.bufferCount % 100 == 0 {
            addLog("ğŸµ å·²å¤„ç† \(AudioCaptureService.bufferCount) ä¸ªéŸ³é¢‘ç¼“å†²åŒºï¼Œå½“å‰ç¼“å†²åŒºå¤§å°: \(buffer.frameLength)")
        }
        
        // å¦‚æœè¾“å…¥æ ¼å¼ä¸ç›®æ ‡æ ¼å¼ç›¸åŒï¼Œç›´æ¥ä½¿ç”¨
        if buffer.format.sampleRate == targetFormat.sampleRate && 
           buffer.format.channelCount == targetFormat.channelCount {
            delegate?.audioCaptureDidReceiveBuffer(buffer)
            return
        }
        
        // éœ€è¦è¿›è¡Œæ ¼å¼è½¬æ¢
        guard let convertedBuffer = convertAudioBuffer(buffer, to: targetFormat) else {
            // è½¬æ¢å¤±è´¥æ—¶è®°å½•æ—¥å¿—ä½†ä¸ä¸­æ–­å¤„ç†
            if AudioCaptureService.bufferCount % 1000 == 0 {
                addLog("âš ï¸ éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œè·³è¿‡æ­¤ç¼“å†²åŒº")
            }
            return
        }
        
        // ä½¿ç”¨è½¬æ¢åçš„ç¼“å†²åŒº
        delegate?.audioCaptureDidReceiveBuffer(convertedBuffer)
    }
    
    /// éŸ³é¢‘æ ¼å¼è½¬æ¢æ–¹æ³•
    /// å°†è¾“å…¥éŸ³é¢‘ç¼“å†²åŒºä»æºæ ¼å¼è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼
    /// - Parameters:
    ///   - sourceBuffer: æºéŸ³é¢‘ç¼“å†²åŒº
    ///   - targetFormat: ç›®æ ‡éŸ³é¢‘æ ¼å¼
    /// - Returns: è½¬æ¢åçš„éŸ³é¢‘ç¼“å†²åŒºï¼Œå¤±è´¥æ—¶è¿”å›nil
    private func convertAudioBuffer(_ sourceBuffer: AVAudioPCMBuffer, to targetFormat: AVAudioFormat) -> AVAudioPCMBuffer? {
        let sourceFormat = sourceBuffer.format
        
        // åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨
        guard let converter = AVAudioConverter(from: sourceFormat, to: targetFormat) else {
            addLog("âŒ æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨")
            return nil
        }
        
        // è®¡ç®—ç›®æ ‡ç¼“å†²åŒºçš„å¸§æ•°
        let capacity = AVAudioFrameCount(Double(sourceBuffer.frameLength) * targetFormat.sampleRate / sourceFormat.sampleRate)
        
        // åˆ›å»ºç›®æ ‡ç¼“å†²åŒº
        guard let targetBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: capacity) else {
            addLog("âŒ æ— æ³•åˆ›å»ºç›®æ ‡éŸ³é¢‘ç¼“å†²åŒº")
            return nil
        }
        
        // é…ç½®è½¬æ¢å™¨å±æ€§ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if sourceFormat.channelCount != targetFormat.channelCount {
            // å•å£°é“/ç«‹ä½“å£°è½¬æ¢
            converter.channelMap = sourceFormat.channelCount > targetFormat.channelCount ? [0] : [0, 0]
        }
        
        // æ‰§è¡ŒéŸ³é¢‘è½¬æ¢
        var error: NSError?
        let inputBlock: AVAudioConverterInputBlock = { inNumPackets, outStatus in
            outStatus.pointee = .haveData
            return sourceBuffer
        }
        
        let status = converter.convert(to: targetBuffer, error: &error, withInputFrom: inputBlock)
        
        // æ£€æŸ¥è½¬æ¢ç»“æœ
        switch status {
        case .haveData:
            // è½¬æ¢æˆåŠŸï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯ï¼ˆé™ä½æ—¥å¿—é¢‘ç‡ï¼‰
            if AudioCaptureService.bufferCount % 2000 == 0 {
                addLog("âœ… éŸ³é¢‘æ ¼å¼è½¬æ¢æˆåŠŸ: \(sourceFormat.sampleRate)Hzâ†’\(targetFormat.sampleRate)Hz, \(sourceFormat.channelCount)â†’\(targetFormat.channelCount)å£°é“")
            }
            return targetBuffer
            
        case .error:
            if let error = error {
                addLog("âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: \(error.localizedDescription)")
            } else {
                addLog("âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: æœªçŸ¥é”™è¯¯")
            }
            return nil
            
        case .inputRanDry:
            addLog("âš ï¸ éŸ³é¢‘è½¬æ¢è¾“å…¥æ•°æ®ä¸è¶³")
            return nil
            
        @unknown default:
            addLog("âš ï¸ éŸ³é¢‘è½¬æ¢è¿”å›æœªçŸ¥çŠ¶æ€")
            return nil
        }
    }
    
    // MARK: - Logging
    
    private func addLog(_ message: String) {
        let timestamp = DateFormatter.logFormatter.string(from: Date())
        let logMessage = "[\(timestamp)] \(message)"
        
        DispatchQueue.main.async {
            self.logs.append(logMessage)
            // Keep only last 100 log entries
            if self.logs.count > 100 {
                self.logs.removeFirst(self.logs.count - 100)
            }
        }
        
        print(logMessage)
    }
}

// MARK: - Error Types

enum AudioCaptureError: LocalizedError {
    case permissionDenied
    case engineSetupFailed
    case captureStartFailed
    case audioSessionError
    
    var errorDescription: String? {
        switch self {
        case .permissionDenied:
            return "éº¦å…‹é£æƒé™è¢«æ‹’ç»"
        case .engineSetupFailed:
            return "éŸ³é¢‘å¼•æ“è®¾ç½®å¤±è´¥"
        case .captureStartFailed:
            return "éŸ³é¢‘é‡‡é›†å¯åŠ¨å¤±è´¥"
        case .audioSessionError:
            return "éŸ³é¢‘ä¼šè¯é…ç½®å¤±è´¥"
        }
    }
}