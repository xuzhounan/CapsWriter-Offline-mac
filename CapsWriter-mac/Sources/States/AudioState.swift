import SwiftUI
import Combine
import AVFoundation

/// éŸ³é¢‘ç›¸å…³çŠ¶æ€ç®¡ç†
/// è´Ÿè´£ç®¡ç†å½•éŸ³æ§åˆ¶ã€éŸ³é¢‘é‡‡é›†æœåŠ¡çŠ¶æ€å’ŒéŸ³é¢‘è®¾å¤‡çŠ¶æ€
class AudioState: ObservableObject {
    
    // MARK: - Published Properties
    
    /// å½“å‰æ˜¯å¦æ­£åœ¨å½•éŸ³
    @Published var isRecording: Bool = false
    
    /// å½•éŸ³å¼€å§‹æ—¶é—´
    @Published var recordingStartTime: Date?
    
    /// éŸ³é¢‘é‡‡é›†æœåŠ¡æ˜¯å¦å‡†å¤‡å°±ç»ª
    @Published var isAudioCaptureServiceReady: Bool = false
    
    /// æ˜¯å¦æœ‰éº¦å…‹é£æƒé™
    @Published var hasMicrophonePermission: Bool = false
    
    /// éŸ³é¢‘é‡‡é›†çŠ¶æ€æè¿°
    @Published var audioCaptureStatus: String = "æœªåˆå§‹åŒ–"
    
    /// éŸ³é¢‘ç¼“å†²åŒºç»Ÿè®¡
    @Published var audioBufferCount: Int = 0
    
    /// éŸ³é¢‘è®¾å¤‡ä¿¡æ¯
    @Published var audioDeviceInfo: AudioDeviceInfo = AudioDeviceInfo()
    
    // MARK: - Private Properties
    
    private let stateQueue = DispatchQueue(label: "com.capswriter.audio-state", attributes: .concurrent)
    private var cancellables = Set<AnyCancellable>()
    
    // MARK: - Singleton
    
    static let shared = AudioState()
    
    private init() {
        setupAudioDeviceMonitoring()
        updateMicrophonePermission()
    }
    
    // MARK: - Recording Control
    
    /// å¼€å§‹å½•éŸ³
    func startRecording() {
        print("ğŸµ AudioState: å¼€å§‹å½•éŸ³")
        DispatchQueue.main.async {
            self.isRecording = true
            self.recordingStartTime = Date()
            self.updateAudioCaptureStatus("å½•éŸ³ä¸­")
        }
        
        // å‘é€å½•éŸ³å¼€å§‹é€šçŸ¥
        NotificationCenter.default.post(
            name: .audioRecordingDidStart,
            object: self
        )
    }
    
    /// åœæ­¢å½•éŸ³
    func stopRecording() {
        print("ğŸ›‘ AudioState: åœæ­¢å½•éŸ³")
        DispatchQueue.main.async {
            self.isRecording = false
            self.recordingStartTime = nil
            self.updateAudioCaptureStatus("å¾…æœº")
        }
        
        // å‘é€å½•éŸ³åœæ­¢é€šçŸ¥
        NotificationCenter.default.post(
            name: .audioRecordingDidStop,
            object: self
        )
    }
    
    /// è·å–å½•éŸ³æŒç»­æ—¶é—´
    var recordingDuration: TimeInterval {
        guard let startTime = recordingStartTime else { return 0 }
        return Date().timeIntervalSince(startTime)
    }
    
    /// æ ¼å¼åŒ–çš„å½•éŸ³æ—¶é•¿æ˜¾ç¤º
    var formattedRecordingDuration: String {
        let duration = recordingDuration
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%02d:%02d", minutes, seconds)
    }
    
    // MARK: - Audio Service Status
    
    /// æ›´æ–°éŸ³é¢‘é‡‡é›†æœåŠ¡çŠ¶æ€
    func updateAudioCaptureServiceStatus(_ isReady: Bool) {
        DispatchQueue.main.async {
            self.isAudioCaptureServiceReady = isReady
            self.updateAudioCaptureStatus(isReady ? "å°±ç»ª" : "æœªå°±ç»ª")
        }
    }
    
    /// æ›´æ–°éŸ³é¢‘é‡‡é›†çŠ¶æ€æè¿°
    func updateAudioCaptureStatus(_ status: String) {
        DispatchQueue.main.async {
            self.audioCaptureStatus = status
        }
    }
    
    /// æ›´æ–°éŸ³é¢‘ç¼“å†²åŒºç»Ÿè®¡
    func updateAudioBufferCount(_ count: Int) {
        DispatchQueue.main.async {
            self.audioBufferCount = count
        }
    }
    
    /// é‡ç½®éŸ³é¢‘ç¼“å†²åŒºç»Ÿè®¡
    func resetAudioBufferCount() {
        DispatchQueue.main.async {
            self.audioBufferCount = 0
        }
    }
    
    // MARK: - Permission Management
    
    /// æ›´æ–°éº¦å…‹é£æƒé™çŠ¶æ€
    func updateMicrophonePermission(_ hasPermission: Bool = false) {
        let permission = hasPermission || (AVCaptureDevice.authorizationStatus(for: .audio) == .authorized)
        
        DispatchQueue.main.async {
            self.hasMicrophonePermission = permission
        }
        
        // å‘é€æƒé™çŠ¶æ€å˜æ›´é€šçŸ¥
        NotificationCenter.default.post(
            name: .microphonePermissionDidChange,
            object: self,
            userInfo: ["hasPermission": permission]
        )
    }
    
    /// è¯·æ±‚éº¦å…‹é£æƒé™
    func requestMicrophonePermission() async -> Bool {
        return await withCheckedContinuation { continuation in
            AVCaptureDevice.requestAccess(for: .audio) { [weak self] granted in
                DispatchQueue.main.async {
                    self?.updateMicrophonePermission(granted)
                    continuation.resume(returning: granted)
                }
            }
        }
    }
    
    /// åˆ·æ–°æƒé™çŠ¶æ€
    func refreshPermissionStatus() {
        updateMicrophonePermission()
    }
    
    // MARK: - Audio Device Management
    
    /// è®¾ç½®éŸ³é¢‘è®¾å¤‡ç›‘æ§
    private func setupAudioDeviceMonitoring() {
        // ç›‘å¬éŸ³é¢‘è®¾å¤‡å˜åŒ–
        NotificationCenter.default.addObserver(
            forName: AVAudioSession.routeChangeNotification,
            object: nil,
            queue: .main
        ) { [weak self] _ in
            self?.updateAudioDeviceInfo()
        }
        
        // åˆå§‹åŒ–è®¾å¤‡ä¿¡æ¯
        updateAudioDeviceInfo()
    }
    
    /// æ›´æ–°éŸ³é¢‘è®¾å¤‡ä¿¡æ¯
    private func updateAudioDeviceInfo() {
        DispatchQueue.main.async {
            self.audioDeviceInfo = AudioDeviceInfo.current()
        }
    }
    
    // MARK: - State Validation
    
    /// éªŒè¯éŸ³é¢‘ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
    var isAudioSystemReady: Bool {
        return hasMicrophonePermission && isAudioCaptureServiceReady
    }
    
    /// è·å–éŸ³é¢‘ç³»ç»ŸçŠ¶æ€æè¿°
    var audioSystemStatusDescription: String {
        if !hasMicrophonePermission {
            return "ç¼ºå°‘éº¦å…‹é£æƒé™"
        } else if !isAudioCaptureServiceReady {
            return "éŸ³é¢‘é‡‡é›†æœåŠ¡æœªå°±ç»ª"
        } else if isRecording {
            return "å½•éŸ³ä¸­ (\(formattedRecordingDuration))"
        } else {
            return "éŸ³é¢‘ç³»ç»Ÿå°±ç»ª"
        }
    }
}

// MARK: - Audio Device Info

/// éŸ³é¢‘è®¾å¤‡ä¿¡æ¯
struct AudioDeviceInfo {
    let inputDeviceName: String
    let sampleRate: Double
    let channelCount: Int
    let bufferDuration: TimeInterval
    
    init(
        inputDeviceName: String = "æœªçŸ¥è®¾å¤‡",
        sampleRate: Double = 0,
        channelCount: Int = 0,
        bufferDuration: TimeInterval = 0
    ) {
        self.inputDeviceName = inputDeviceName
        self.sampleRate = sampleRate
        self.channelCount = channelCount
        self.bufferDuration = bufferDuration
    }
    
    /// è·å–å½“å‰éŸ³é¢‘è®¾å¤‡ä¿¡æ¯
    static func current() -> AudioDeviceInfo {
        let audioSession = AVAudioSession.sharedInstance()
        
        return AudioDeviceInfo(
            inputDeviceName: audioSession.currentRoute.inputs.first?.portName ?? "æœªçŸ¥è®¾å¤‡",
            sampleRate: audioSession.sampleRate,
            channelCount: Int(audioSession.inputNumberOfChannels),
            bufferDuration: audioSession.ioBufferDuration
        )
    }
}

// MARK: - Notification Names

extension Notification.Name {
    static let audioRecordingDidStart = Notification.Name("audioRecordingDidStart")
    static let audioRecordingDidStop = Notification.Name("audioRecordingDidStop")
    static let microphonePermissionDidChange = Notification.Name("microphonePermissionDidChange")
}

// MARK: - Extensions

extension AudioState {
    
    /// è°ƒè¯•ä¿¡æ¯
    var debugDescription: String {
        return """
        AudioState Debug Info:
        - Recording: \(isRecording)
        - Duration: \(formattedRecordingDuration)
        - Microphone Permission: \(hasMicrophonePermission)
        - Service Ready: \(isAudioCaptureServiceReady)
        - Status: \(audioCaptureStatus)
        - Buffer Count: \(audioBufferCount)
        - Device: \(audioDeviceInfo.inputDeviceName)
        - Sample Rate: \(audioDeviceInfo.sampleRate)Hz
        """
    }
    
    /// é‡ç½®æ‰€æœ‰çŠ¶æ€
    func resetAllStates() {
        DispatchQueue.main.async {
            self.isRecording = false
            self.recordingStartTime = nil
            self.isAudioCaptureServiceReady = false
            self.audioCaptureStatus = "æœªåˆå§‹åŒ–"
            self.audioBufferCount = 0
        }
        
        print("ğŸ”„ AudioState: æ‰€æœ‰çŠ¶æ€å·²é‡ç½®")
    }
}