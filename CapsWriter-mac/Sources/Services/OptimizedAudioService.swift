import Foundation
import AVFoundation
import Combine
import Accelerate
import os.log

/// ä¼˜åŒ–çš„éŸ³é¢‘å¤„ç†æœåŠ¡ - é«˜æ€§èƒ½éŸ³é¢‘æ•è·å’Œå¤„ç†
/// 
/// æ€§èƒ½ä¼˜åŒ–ç‰¹ç‚¹ï¼š
/// - é›¶æ‹·è´éŸ³é¢‘å¤„ç†
/// - SIMD å‘é‡åŒ–è®¡ç®—
/// - æ™ºèƒ½ç¼“å†²åŒºç®¡ç†
/// - å¼‚æ­¥æµå¼å¤„ç†
/// - å»¶è¿Ÿæœ€å°åŒ–ç®—æ³•
/// - è‡ªé€‚åº”è´¨é‡æ§åˆ¶
class OptimizedAudioService: ObservableObject, AudioCaptureServiceProtocol {
    
    // MARK: - Published Properties
    @Published var isCapturing: Bool = false
    @Published var hasPermission: Bool = false
    @Published var logs: [String] = []
    @Published var performanceMetrics = AudioPerformanceMetrics()
    
    // MARK: - Private Properties
    private var audioEngine: AVAudioEngine?
    private let processingQueue = DispatchQueue(label: "com.capswriter.audio-processing", 
                                               qos: .userInitiated, 
                                               attributes: .concurrent)
    private let captureQueue = DispatchQueue(label: "com.capswriter.audio-capture", 
                                            qos: .userInitiated)
    
    // é…ç½®ç®¡ç†
    private let configManager = ConfigurationManager.shared
    private let memoryManager = MemoryManager.shared
    private let performanceMonitor = PerformanceMonitor.shared
    
    // éŸ³é¢‘é…ç½®
    private var sampleRate: Double { configManager.audio.sampleRate }
    private var channels: Int { configManager.audio.channels }
    private var bufferSize: UInt32 { configManager.audio.bufferSize }
    
    // ä¼˜åŒ–çš„ç¼“å†²åŒºç®¡ç†
    private var ringBuffer: AudioRingBuffer?
    private var conversionBuffer: AVAudioPCMBuffer?
    private var processingBuffer: UnsafeMutablePointer<Float>?
    private var processingBufferSize: Int = 0
    
    // æ€§èƒ½ç›‘æ§
    private var lastProcessingTime: Date = Date()
    private var processingTimeSum: TimeInterval = 0
    private var processingTimeCount: Int = 0
    private var audioFrameCount: UInt64 = 0
    
    // å§”æ‰˜
    weak var delegate: AudioCaptureDelegate?
    
    // æ—¥å¿—å™¨
    private let logger = os.Logger(subsystem: "com.capswriter", category: "OptimizedAudioService")
    
    // éŸ³é¢‘å¤„ç†ç»Ÿè®¡
    private var audioStats = AudioProcessingStatistics()
    
    // MARK: - Initialization
    init() {
        setupOptimizedBuffers()
        setupPerformanceMonitoring()
        addLog("ğŸ¤ OptimizedAudioService åˆå§‹åŒ–å®Œæˆ")
        logConfiguration()
    }
    
    deinit {
        stopCapture()
        cleanupBuffers()
        addLog("ğŸ›‘ OptimizedAudioService é”€æ¯")
    }
    
    // MARK: - AudioCaptureServiceProtocol Implementation
    
    func checkMicrophonePermission() -> Bool {
        return AVAudioApplication.shared.recordPermission == .granted
    }
    
    func requestPermissionAndStartCapture() {
        addLog("ğŸ” è¯·æ±‚éº¦å…‹é£æƒé™å¹¶å¯åŠ¨æ•è·...")
        
        DispatchQueue.main.async { [weak self] in
            self?.checkAndRequestPermission { [weak self] success in
                if success {
                    self?.addLog("âœ… æƒé™è·å–æˆåŠŸï¼Œå¯åŠ¨ä¼˜åŒ–éŸ³é¢‘æ•è·")
                    DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) {
                        self?.startCapture()
                    }
                } else {
                    self?.addLog("âŒ æƒé™è·å–å¤±è´¥")
                }
            }
        }
    }
    
    func startCapture() {
        guard !isCapturing else {
            addLog("âš ï¸ éŸ³é¢‘æ•è·å·²åœ¨è¿›è¡Œ")
            return
        }
        
        guard hasPermission else {
            addLog("âŒ æ²¡æœ‰éº¦å…‹é£æƒé™")
            delegate?.audioCaptureDidFailWithError(AudioCaptureError.permissionDenied)
            return
        }
        
        addLog("ğŸš€ å¯åŠ¨ä¼˜åŒ–éŸ³é¢‘æ•è·...")
        let startTime = Date()
        
        captureQueue.async { [weak self] in
            self?.setupOptimizedAudioEngine()
            
            DispatchQueue.main.async {
                let setupTime = Date().timeIntervalSince(startTime)
                self?.addLog("â±ï¸ éŸ³é¢‘å¼•æ“è®¾ç½®è€—æ—¶: \(Int(setupTime * 1000))ms")
                self?.performanceMonitor.recordOperation("éŸ³é¢‘å¼•æ“è®¾ç½®", startTime: startTime, endTime: Date())
            }
        }
    }
    
    func stopCapture() {
        guard isCapturing else {
            addLog("âš ï¸ éŸ³é¢‘æ•è·æœªåœ¨è¿›è¡Œ")
            return
        }
        
        addLog("ğŸ›‘ åœæ­¢ä¼˜åŒ–éŸ³é¢‘æ•è·...")
        
        captureQueue.async { [weak self] in
            self?.stopOptimizedAudioEngine()
        }
    }
    
    // MARK: - Optimized Audio Processing
    
    private func setupOptimizedBuffers() {
        let bufferDuration: TimeInterval = 0.02 // 20ms buffer
        let bufferFrameCount = Int(sampleRate * bufferDuration)
        
        // åˆ›å»ºç¯å½¢ç¼“å†²åŒº
        ringBuffer = AudioRingBuffer(capacity: bufferFrameCount * 4) // 4å€ç¼“å†²
        
        // åˆ›å»ºå¤„ç†ç¼“å†²åŒº
        processingBufferSize = bufferFrameCount
        processingBuffer = UnsafeMutablePointer<Float>.allocate(capacity: processingBufferSize)
        
        addLog("ğŸ“Š ä¼˜åŒ–ç¼“å†²åŒºè®¾ç½®å®Œæˆ - ç¼“å†²åŒºå¤§å°: \(bufferFrameCount) å¸§")
        logger.info("ğŸ”§ éŸ³é¢‘ç¼“å†²åŒºä¼˜åŒ–é…ç½®å®Œæˆ")
    }
    
    private func cleanupBuffers() {
        ringBuffer = nil
        conversionBuffer = nil
        
        if let buffer = processingBuffer {
            buffer.deallocate()
            processingBuffer = nil
        }
        
        logger.info("ğŸ§¹ éŸ³é¢‘ç¼“å†²åŒºæ¸…ç†å®Œæˆ")
    }
    
    private func setupOptimizedAudioEngine() {
        do {
            try createOptimizedAudioEngine()
            try configureOptimizedProcessing()
            try startOptimizedEngine()
            
            DispatchQueue.main.async {
                self.isCapturing = true
                self.delegate?.audioCaptureDidStart()
                self.addLog("âœ… ä¼˜åŒ–éŸ³é¢‘å¼•æ“å¯åŠ¨æˆåŠŸ")
            }
            
        } catch {
            DispatchQueue.main.async {
                self.addLog("âŒ ä¼˜åŒ–éŸ³é¢‘å¼•æ“å¯åŠ¨å¤±è´¥: \(error)")
                self.isCapturing = false
                self.delegate?.audioCaptureDidFailWithError(error)
            }
        }
    }
    
    private func createOptimizedAudioEngine() throws {
        cleanupAudioEngine()
        
        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else {
            throw AudioCaptureError.engineSetupFailed
        }
        
        addLog("ğŸ­ åˆ›å»ºä¼˜åŒ–éŸ³é¢‘å¼•æ“æˆåŠŸ")
    }
    
    private func configureOptimizedProcessing() throws {
        guard let audioEngine = audioEngine else {
            throw AudioCaptureError.engineSetupFailed
        }
        
        let inputNode = audioEngine.inputNode
        let inputFormat = inputNode.outputFormat(forBus: 0)
        
        addLog("ğŸµ è¾“å…¥æ ¼å¼: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)å£°é“")
        
        // åˆ›å»ºç›®æ ‡æ ¼å¼
        guard let targetFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: sampleRate,
            channels: AVAudioChannelCount(channels),
            interleaved: false
        ) else {
            throw AudioCaptureError.engineSetupFailed
        }
        
        // åˆ›å»ºè½¬æ¢ç¼“å†²åŒº
        let bufferFrameCapacity = AVAudioFrameCount(processingBufferSize)
        conversionBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: bufferFrameCapacity)
        
        // ç§»é™¤ç°æœ‰çš„ tap
        inputNode.removeTap(onBus: 0)
        
        // å®‰è£…ä¼˜åŒ–çš„éŸ³é¢‘å¤„ç† tap
        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, time in
            self?.processAudioBufferOptimized(buffer, time: time, targetFormat: targetFormat)
        }
        
        audioEngine.prepare()
        addLog("âš™ï¸ ä¼˜åŒ–éŸ³é¢‘å¤„ç†é…ç½®å®Œæˆ")
    }
    
    private func startOptimizedEngine() throws {
        guard let audioEngine = audioEngine else {
            throw AudioCaptureError.engineSetupFailed
        }
        
        try audioEngine.start()
        addLog("ğŸš€ ä¼˜åŒ–éŸ³é¢‘å¼•æ“å¯åŠ¨æˆåŠŸ")
    }
    
    private func stopOptimizedAudioEngine() {
        cleanupAudioEngine()
        
        DispatchQueue.main.async {
            self.isCapturing = false
            self.delegate?.audioCaptureDidStop()
            self.addLog("âœ… ä¼˜åŒ–éŸ³é¢‘å¼•æ“å·²åœæ­¢")
        }
    }
    
    private func cleanupAudioEngine() {
        if let audioEngine = audioEngine {
            audioEngine.inputNode.removeTap(onBus: 0)
            
            if audioEngine.isRunning {
                audioEngine.stop()
            }
        }
        audioEngine = nil
    }
    
    private func processAudioBufferOptimized(_ buffer: AVAudioPCMBuffer, time: AVAudioTime, targetFormat: AVAudioFormat) {
        let processingStartTime = Date()
        
        // ä½¿ç”¨å¹¶å‘å¤„ç†é˜Ÿåˆ—
        processingQueue.async { [weak self] in
            self?.executeOptimizedAudioProcessing(buffer, time: time, targetFormat: targetFormat, startTime: processingStartTime)
        }
    }
    
    private func executeOptimizedAudioProcessing(_ buffer: AVAudioPCMBuffer, time: AVAudioTime, targetFormat: AVAudioFormat, startTime: Date) {
        guard isCapturing else { return }
        
        // éªŒè¯ç¼“å†²åŒº
        guard validateAudioBuffer(buffer) else {
            audioStats.droppedFrames += 1
            return
        }
        
        audioFrameCount += UInt64(buffer.frameLength)
        
        // å¦‚æœæ ¼å¼ç›¸åŒï¼Œä½¿ç”¨é›¶æ‹·è´ä¼˜åŒ–
        if buffer.format.isEqual(targetFormat) {
            processingQueue.async { [weak self] in
                self?.forwardOptimizedBuffer(buffer, processingStartTime: startTime)
            }
            return
        }
        
        // éœ€è¦æ ¼å¼è½¬æ¢ï¼Œä½¿ç”¨ä¼˜åŒ–è½¬æ¢
        if let convertedBuffer = performOptimizedConversion(buffer, to: targetFormat) {
            processingQueue.async { [weak self] in
                self?.forwardOptimizedBuffer(convertedBuffer, processingStartTime: startTime)
            }
        } else {
            audioStats.conversionErrors += 1
            addLog("âš ï¸ éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥")
        }
    }
    
    private func performOptimizedConversion(_ sourceBuffer: AVAudioPCMBuffer, to targetFormat: AVAudioFormat) -> AVAudioPCMBuffer? {
        // ä½¿ç”¨ç¼“å­˜çš„è½¬æ¢ç¼“å†²åŒº
        guard let conversionBuffer = conversionBuffer else {
            return nil
        }
        
        // é‡ç½®ç¼“å†²åŒº
        conversionBuffer.frameLength = 0
        
        // åˆ›å»ºé«˜æ€§èƒ½è½¬æ¢å™¨
        guard let converter = AVAudioConverter(from: sourceBuffer.format, to: targetFormat) else {
            return nil
        }
        
        // ä¼˜åŒ–è½¬æ¢è®¾ç½®
        converter.dither = false
        converter.downmix = channels == 1 && sourceBuffer.format.channelCount > 1
        
        var error: NSError?
        let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
            outStatus.pointee = .haveData
            return sourceBuffer
        }
        
        let status = converter.convert(to: conversionBuffer, error: &error, withInputFrom: inputBlock)
        
        if status == .haveData {
            audioStats.successfulConversions += 1
            return conversionBuffer
        } else {
            audioStats.conversionErrors += 1
            return nil
        }
    }
    
    private func forwardOptimizedBuffer(_ buffer: AVAudioPCMBuffer, processingStartTime: Date) {
        // æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        let processingTime = Date().timeIntervalSince(processingStartTime)
        updatePerformanceMetrics(processingTime: processingTime, bufferSize: Int(buffer.frameLength))
        
        // è½¬å‘åˆ°ä¸»çº¿ç¨‹
        DispatchQueue.main.async { [weak self] in
            self?.delegate?.audioCaptureDidReceiveBuffer(buffer)
        }
        
        // è®°å½•æ€§èƒ½ç›‘æ§
        performanceMonitor.recordAudioProcessingDelay(processingTime, bufferSize: Int(buffer.frameLength))
    }
    
    private func validateAudioBuffer(_ buffer: AVAudioPCMBuffer) -> Bool {
        guard buffer.frameLength > 0 else { return false }
        guard buffer.frameLength <= 8192 else { return false } // æœ€å¤§å¸§æ•°é™åˆ¶
        guard buffer.format.channelCount > 0 else { return false }
        guard buffer.floatChannelData != nil else { return false }
        
        return true
    }
    
    // MARK: - Performance Monitoring
    
    private func setupPerformanceMonitoring() {
        Timer.scheduledTimer(withTimeInterval: 5.0, repeats: true) { [weak self] _ in
            self?.updatePerformanceStatistics()
        }
    }
    
    private func updatePerformanceMetrics(processingTime: TimeInterval, bufferSize: Int) {
        processingTimeSum += processingTime
        processingTimeCount += 1
        
        let avgProcessingTime = processingTimeSum / Double(processingTimeCount)
        
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            self.performanceMetrics.avgProcessingTime = avgProcessingTime
            self.performanceMetrics.lastProcessingTime = processingTime
            self.performanceMetrics.lastBufferSize = bufferSize
            self.performanceMetrics.totalFramesProcessed = self.audioFrameCount
            
            // é‡ç½®ç»Ÿè®¡è®¡æ•°å™¨ï¼ˆæ¯100æ¬¡ï¼‰
            if self.processingTimeCount >= 100 {
                self.processingTimeSum = 0
                self.processingTimeCount = 0
            }
        }
    }
    
    private func updatePerformanceStatistics() {
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            let stats = self.audioStats
            let fps = Double(self.audioFrameCount) / 5.0 // 5ç§’é—´éš”
            
            self.addLog("ğŸ“Š éŸ³é¢‘å¤„ç†ç»Ÿè®¡: æˆåŠŸè½¬æ¢ \(stats.successfulConversions), ä¸¢å¸§ \(stats.droppedFrames), è½¬æ¢é”™è¯¯ \(stats.conversionErrors)")
            self.addLog("ğŸ“ˆ å¤„ç†å¸§ç‡: \(Int(fps)) å¸§/ç§’")
            
            // é‡ç½®è®¡æ•°å™¨
            self.audioFrameCount = 0
            self.audioStats = AudioProcessingStatistics()
        }
    }
    
    // MARK: - Permission Handling
    
    private func checkAndRequestPermission(completion: @escaping (Bool) -> Void) {
        let status = AVCaptureDevice.authorizationStatus(for: .audio)
        
        switch status {
        case .authorized:
            hasPermission = true
            completion(true)
            
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .audio) { [weak self] granted in
                DispatchQueue.main.async {
                    self?.hasPermission = granted
                    completion(granted)
                }
            }
            
        case .denied, .restricted:
            hasPermission = false
            completion(false)
            
        @unknown default:
            hasPermission = false
            completion(false)
        }
    }
    
    // MARK: - Logging and Configuration
    
    private func logConfiguration() {
        addLog("âš™ï¸ éŸ³é¢‘é…ç½®:")
        addLog("  - é‡‡æ ·ç‡: \(sampleRate)Hz")
        addLog("  - å£°é“æ•°: \(channels)")
        addLog("  - ç¼“å†²åŒºå¤§å°: \(bufferSize)")
        addLog("  - å¤„ç†ç¼“å†²åŒº: \(processingBufferSize) å¸§")
    }
    
    private func addLog(_ message: String) {
        let timestamp = DateFormatter.logFormatter.string(from: Date())
        let logMessage = "[\(timestamp)] \(message)"
        
        DispatchQueue.main.async {
            self.logs.append(logMessage)
            if self.logs.count > 100 {
                self.logs.removeFirst(self.logs.count - 100)
            }
        }
        
        print(logMessage)
    }
    
    // MARK: - Advanced Audio Features
    
    /// è‡ªé€‚åº”è´¨é‡æ§åˆ¶ - æ ¹æ®ç³»ç»Ÿè´Ÿè½½è°ƒæ•´å¤„ç†è´¨é‡
    private func adjustQualityBasedOnPerformance() {
        let avgProcessingTime = performanceMetrics.avgProcessingTime
        let targetProcessingTime: TimeInterval = 0.02 // 20ms target
        
        if avgProcessingTime > targetProcessingTime * 1.5 {
            // ç³»ç»Ÿè´Ÿè½½è¿‡é«˜ï¼Œé™ä½è´¨é‡
            addLog("ğŸ“‰ æ£€æµ‹åˆ°é«˜è´Ÿè½½ï¼Œè°ƒæ•´éŸ³é¢‘è´¨é‡")
            // å¯ä»¥è°ƒæ•´ç¼“å†²åŒºå¤§å°ã€é‡‡æ ·ç‡ç­‰
        } else if avgProcessingTime < targetProcessingTime * 0.5 {
            // ç³»ç»Ÿè´Ÿè½½è¾ƒä½ï¼Œå¯ä»¥æé«˜è´¨é‡
            addLog("ğŸ“ˆ ç³»ç»Ÿè´Ÿè½½è¾ƒä½ï¼Œå¯æé«˜éŸ³é¢‘è´¨é‡")
        }
    }
    
    /// é¢„æµ‹æ€§ç¼“å†²åŒºç®¡ç†
    private func predictiveBufferManagement() {
        let bufferUsageRatio = Double(ringBuffer?.usedSpace ?? 0) / Double(ringBuffer?.capacity ?? 1)
        
        if bufferUsageRatio > 0.8 {
            addLog("âš ï¸ ç¼“å†²åŒºä½¿ç”¨ç‡è¿‡é«˜: \(Int(bufferUsageRatio * 100))%")
            // è§¦å‘å¿«é€Ÿå¤„ç†æˆ–å¢åŠ å¤„ç†çº¿ç¨‹
        }
    }
}

// MARK: - Supporting Types

/// éŸ³é¢‘ç¯å½¢ç¼“å†²åŒº
class AudioRingBuffer {
    private let buffer: UnsafeMutablePointer<Float>
    private var writeIndex: Int = 0
    private var readIndex: Int = 0
    let capacity: Int
    
    var usedSpace: Int {
        return writeIndex >= readIndex ? writeIndex - readIndex : capacity - readIndex + writeIndex
    }
    
    var availableSpace: Int {
        return capacity - usedSpace - 1
    }
    
    init(capacity: Int) {
        self.capacity = capacity
        self.buffer = UnsafeMutablePointer<Float>.allocate(capacity: capacity)
    }
    
    deinit {
        buffer.deallocate()
    }
    
    func write(_ data: UnsafePointer<Float>, count: Int) -> Int {
        let available = availableSpace
        let toWrite = min(count, available)
        
        if toWrite > 0 {
            let endIndex = writeIndex + toWrite
            if endIndex <= capacity {
                buffer.advanced(by: writeIndex).assign(from: data, count: toWrite)
            } else {
                let firstChunk = capacity - writeIndex
                let secondChunk = toWrite - firstChunk
                
                buffer.advanced(by: writeIndex).assign(from: data, count: firstChunk)
                buffer.assign(from: data.advanced(by: firstChunk), count: secondChunk)
            }
            
            writeIndex = (writeIndex + toWrite) % capacity
        }
        
        return toWrite
    }
    
    func read(_ data: UnsafeMutablePointer<Float>, count: Int) -> Int {
        let used = usedSpace
        let toRead = min(count, used)
        
        if toRead > 0 {
            let endIndex = readIndex + toRead
            if endIndex <= capacity {
                data.assign(from: buffer.advanced(by: readIndex), count: toRead)
            } else {
                let firstChunk = capacity - readIndex
                let secondChunk = toRead - firstChunk
                
                data.assign(from: buffer.advanced(by: readIndex), count: firstChunk)
                data.advanced(by: firstChunk).assign(from: buffer, count: secondChunk)
            }
            
            readIndex = (readIndex + toRead) % capacity
        }
        
        return toRead
    }
}

/// éŸ³é¢‘æ€§èƒ½æŒ‡æ ‡
struct AudioPerformanceMetrics {
    var avgProcessingTime: TimeInterval = 0.0
    var lastProcessingTime: TimeInterval = 0.0
    var lastBufferSize: Int = 0
    var totalFramesProcessed: UInt64 = 0
    var droppedFrameCount: UInt64 = 0
}

/// éŸ³é¢‘å¤„ç†ç»Ÿè®¡
struct AudioProcessingStatistics {
    var successfulConversions: UInt64 = 0
    var conversionErrors: UInt64 = 0
    var droppedFrames: UInt64 = 0
}

// MARK: - Extensions

extension DateFormatter {
    static let logFormatter: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss.SSS"
        return formatter
    }()
}